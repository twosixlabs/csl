{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Load data files\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "url_x = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_x.npy'\n",
    "url_y = 'https://github.com/jnear/cs211-data-privacy/raw/master/slides/adult_processed_y.npy'\n",
    "\n",
    "with urllib.request.urlopen(url_x) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "X = np.load(f)\n",
    "\n",
    "with urllib.request.urlopen(url_y) as url:\n",
    "    f = io.BytesIO(url.read())\n",
    "y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mech_zCDP_vec(vec, sensitivity, rho):\n",
    "    sigma = np.sqrt((sensitivity**2) / (2 * rho))\n",
    "    return vec + np.random.normal(loc=0, scale=sigma, size=vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test set sizes: 36176 9044\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "training_size = int(X.shape[0] * 0.8)\n",
    "\n",
    "X_train = X[:training_size]\n",
    "X_test = X[training_size:]\n",
    "\n",
    "y_train = y[:training_size]\n",
    "y_test = y[training_size:]\n",
    "\n",
    "print('Train and test set sizes:', len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clipping and Gradient definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_clip_array(vs , b):\n",
    "    norms = np.linalg.norm(vs, ord = 2, axis = 1)\n",
    "    ratios = vs/norms[:, None]\n",
    "    results = np.where((norms > b)[:, None], b*ratios, vs)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgradient(theta_in, x_in, y_in, C):\n",
    "    x = x_in\n",
    "    y = y_in\n",
    "    theta = theta_in\n",
    "    exponent = y * np.dot(x, theta)\n",
    "    rhs = (y/(1+np.exp(exponent)))\n",
    "    gradients = -(x*rhs[:, None])\n",
    "    return gradients\n",
    "#     clipped_grads = L2_clip_array(gradients, C)\n",
    "#     return np.sum(clipped_grads, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction: take a model (theta) and a single example (xi) and return its predicted label\n",
    "def predict(xi, theta, bias=0):\n",
    "    label = np.sign(xi @ theta + bias)\n",
    "    return label\n",
    "\n",
    "def accuracy(theta):\n",
    "    return np.sum(predict(X_test, theta) == y_test)/X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline (gradient clipping DP-SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential mechanism, k times\n",
    "# sat rho-zCDP\n",
    "def top_k(grads, C, k, rho):\n",
    "    rho_i = rho / k\n",
    "    clipped_grads = np.clip(grads, -.1, .1)\n",
    "    avg_grad = np.mean(clipped_grads, axis=0)\n",
    "    sens = 1 / len(grads)\n",
    "    noise = np.random.gumbel(loc=0, scale=sens/np.sqrt(8*rho_i), size=len(avg_grad))\n",
    "    noisy_scores = np.abs(avg_grad) + noise\n",
    "    k_ind = np.argpartition(noisy_scores, -k)[-k:]\n",
    "    return k_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_gradient_descent(epochs, rho, k=20, clipping_param=.3):\n",
    "    rho_i = rho/epochs\n",
    "    d = X_train.shape[1]\n",
    "    theta = np.zeros(d)                 # leaks the number of features, without privacy\n",
    "    num_examples = X_train.shape[0]     # leaks the number of training examples, without privacy\n",
    "\n",
    "    BATCH_SIZE = 256\n",
    "    num_batches = int(num_examples / BATCH_SIZE)\n",
    "    batches_X = np.array_split(X, num_batches)\n",
    "    batches_y = np.array_split(y, num_batches)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        for xs, ys in zip(batches_X, batches_y):\n",
    "            grads           = vgradient(theta, xs, ys, clipping_param)\n",
    "            \n",
    "            # this is not private yet\n",
    "            k_ind_old       = np.argpartition(np.abs(np.mean(grads, axis=0)), -k)[-k:]\n",
    "            k_ind           = top_k(grads, None, k, .1*rho_i)\n",
    "            k_grads         = grads[:, k_ind]\n",
    "            #print('old k_ind:', k_ind_old, 'new k_ind:', k_ind)\n",
    "            \n",
    "            # clip just the chosen parameters\n",
    "            clipped_grads   = L2_clip_array(k_grads, clipping_param)\n",
    "            avg_grad        = np.mean(clipped_grads, axis=0) # sensitivity is clipping_param / len(xs)\n",
    "            noisy_grad      = gaussian_mech_zCDP_vec(avg_grad, clipping_param/len(xs), .9*rho_i)\n",
    "            full_grad       = np.zeros(d)\n",
    "            full_grad[k_ind]= noisy_grad\n",
    "            #print(full_grad)\n",
    "            #theta           = theta - full_grad       # regular version\n",
    "            theta            = theta - (.5/(i+5))*np.sign(full_grad)     # sign version\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21559660262893474"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def zcdp_eps(rho, delta):\n",
    "    return rho + 2*np.sqrt(rho * np.log(1/delta))\n",
    "zcdp_eps(0.001, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps: 0.21559660262893474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnear/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.786985846970367\n",
      "std: 0.007927877162696766\n"
     ]
    }
   ],
   "source": [
    "rho = .001\n",
    "epochs = 10\n",
    "print('eps:', zcdp_eps(rho, 1e-5))\n",
    "accs = [accuracy(dp_gradient_descent(epochs, rho, k=30)) for _ in range(10)]\n",
    "print('mean:', np.mean(accs))\n",
    "print('std:', np.std(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnear/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "ks = [1, 10, 20, 50, 70, 100]\n",
    "ks = np.linspace(10, 80, 40)\n",
    "runs = 20\n",
    "means = []\n",
    "stds = []\n",
    "for k in ks:\n",
    "    print(k)\n",
    "    accs = [accuracy(dp_gradient_descent(epochs, rho)) for _ in range(runs)]\n",
    "    means.append(np.mean(accs))\n",
    "    stds.append(np.std(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(ks, means, yerr=stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
