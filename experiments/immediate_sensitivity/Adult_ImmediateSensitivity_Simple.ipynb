{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "po_2rTwrOiEf",
    "outputId": "e38f056c-a0a8-438f-b65c-df5ad9b214ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from IPython import display\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(7)\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\n",
    "\n",
    "%matplotlib inline\n",
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility for loading up the dataset\n",
    "\n",
    "def load_adult_data(path):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "                    'martial_status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                    'capital_gain', 'capital_loss', 'hours_per_week', 'country', 'target']\n",
    "    input_data = (pd.read_csv(path, names=column_names,\n",
    "                              na_values=\"?\", sep=r'\\s*,\\s*', engine='python')\n",
    "                  .loc[lambda df: df['race'].isin(['White', 'Black'])])\n",
    "\n",
    "    # targets; 1 when someone makes over 50k , otherwise 0\n",
    "    y = (input_data['target'] == '>50K').astype(int)\n",
    "\n",
    "    # features; note that the 'target' and sentive attribute columns are dropped\n",
    "    X = (input_data\n",
    "         .drop(columns=['target', 'fnlwgt'])\n",
    "         .fillna('Unknown')\n",
    "         .pipe(pd.get_dummies, drop_first=True))\n",
    "\n",
    "    y = y.to_frame()\n",
    "    for col in X.columns:\n",
    "      X[col] = X[col].astype('float32')\n",
    "\n",
    "    for col in y.columns:\n",
    "      y[col] = y[col].astype('float32')\n",
    "\n",
    "    print(f\"features X: {X.shape[0]} samples, {X.shape[1]} attributes\")\n",
    "    print(f\"targets y: {y.shape} samples\")\n",
    "    return X, y\n",
    "\n",
    "class PandasDataSet(TensorDataset):\n",
    "    def __init__(self, *dataframes):\n",
    "        tensors = (self._df_to_tensor(df) for df in dataframes)\n",
    "        super(PandasDataSet, self).__init__(*tensors)\n",
    "\n",
    "    def _df_to_tensor(self, df):\n",
    "        if isinstance(df, pd.Series):\n",
    "            df = df.to_frame('dummy')\n",
    "        return torch.from_numpy(df.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "Li30_V7YPtg-",
    "outputId": "b554e383-a5ba-4912-8900-a9ee9fe59c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features X: 30940 samples, 95 attributes\n",
      "targets y: (30940, 1) samples\n",
      "        age  education_num  capital_gain  capital_loss  hours_per_week  \\\n",
      "27719  17.0            7.0           0.0           0.0            12.0   \n",
      "936    47.0           14.0           0.0           0.0            25.0   \n",
      "3936   46.0           11.0           0.0           0.0            38.0   \n",
      "8500   45.0           14.0           0.0        1902.0            50.0   \n",
      "3882   51.0           10.0           0.0           0.0            40.0   \n",
      "\n",
      "       workclass_Local-gov  workclass_Never-worked  workclass_Private  \\\n",
      "27719                  0.0                     0.0                1.0   \n",
      "936                    0.0                     0.0                1.0   \n",
      "3936                   0.0                     0.0                0.0   \n",
      "8500                   0.0                     0.0                1.0   \n",
      "3882                   0.0                     0.0                1.0   \n",
      "\n",
      "       workclass_Self-emp-inc  workclass_Self-emp-not-inc  ...  \\\n",
      "27719                     0.0                         0.0  ...   \n",
      "936                       0.0                         0.0  ...   \n",
      "3936                      0.0                         0.0  ...   \n",
      "8500                      0.0                         0.0  ...   \n",
      "3882                      0.0                         0.0  ...   \n",
      "\n",
      "       country_Puerto-Rico  country_Scotland  country_South  country_Taiwan  \\\n",
      "27719                  0.0               0.0            0.0             0.0   \n",
      "936                    0.0               0.0            0.0             0.0   \n",
      "3936                   0.0               0.0            0.0             0.0   \n",
      "8500                   0.0               0.0            0.0             0.0   \n",
      "3882                   0.0               0.0            0.0             0.0   \n",
      "\n",
      "       country_Thailand  country_Trinadad&Tobago  country_United-States  \\\n",
      "27719               0.0                      0.0                    1.0   \n",
      "936                 0.0                      0.0                    1.0   \n",
      "3936                0.0                      0.0                    1.0   \n",
      "8500                0.0                      0.0                    1.0   \n",
      "3882                0.0                      0.0                    1.0   \n",
      "\n",
      "       country_Unknown  country_Vietnam  country_Yugoslavia  \n",
      "27719              0.0              0.0                 0.0  \n",
      "936                0.0              0.0                 0.0  \n",
      "3936               0.0              0.0                 0.0  \n",
      "8500               0.0              0.0                 0.0  \n",
      "3882               0.0              0.0                 0.0  \n",
      "\n",
      "[5 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "# load adult data set\n",
    "path = 'adult.data'\n",
    "# path = 'adult.data'\n",
    "X, y = load_adult_data(path)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# split into train/test set\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, stratify=y, random_state=7)\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "xIajW8C6RRlz",
    "outputId": "80b2c04d-0728-480c-fe05-a96124a967e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training samples: 24752\n",
      "# testing samples: 6188\n",
      "# batches: 1547\n",
      "# training samples: 6188\n",
      "# batches: 364\n"
     ]
    }
   ],
   "source": [
    "# Set up training & testing data\n",
    "\n",
    "train_data = PandasDataSet(X_train, y_train)\n",
    "test_data = PandasDataSet(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, drop_last=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=17, shuffle=False, drop_last=True)\n",
    "\n",
    "print('# training samples:', len(train_data))\n",
    "print('# testing samples:', len(test_data))\n",
    "print('# batches:', len(train_loader))\n",
    "\n",
    "print('# training samples:', len(test_data))\n",
    "print('# batches:', len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define accuracy & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, test_loader):\n",
    "    correct = 0\n",
    "\n",
    "    for examples, labels in test_loader:\n",
    "        output = model.forward(examples)\n",
    "        batch_correct = torch.sum(torch.abs(output - labels) < 0.5)\n",
    "        correct += batch_correct\n",
    "\n",
    "    acc = float(correct)/len(test_data)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=32, p_dropout=0.2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.network(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The calculation for immediate sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_immediate_sensitivity(model, criterion, inputs, labels, epoch):\n",
    "    inp = Variable(inputs, requires_grad=True)\n",
    "    \n",
    "    outputs = model.forward(inp)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # (1) first-order gradient (wrt parameters)\n",
    "    first_order_grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True, create_graph=True)\n",
    "    \n",
    "    # (2) L2 norm of the gradient from (1)\n",
    "    grad_l2_norm = torch.norm(torch.cat([x.view(-1) for x in first_order_grads]), p = 2)\n",
    "    \n",
    "    # (3) Gradient (wrt inputs) of the L2 norm of the gradient from (2)\n",
    "    sensitivity_vec = torch.autograd.grad(grad_l2_norm, inp, retain_graph=True)[0]\n",
    "    \n",
    "    # (4) L2 norm of (3) - \"immediate sensitivity\"\n",
    "    s = [torch.norm(v, p=2).numpy().item() for v in sensitivity_vec]\n",
    "    \n",
    "    '''\n",
    "    if epoch > 5:\n",
    "        print(f\"inputs: \",inp)\n",
    "        print(f\"outputs: \", outputs)\n",
    "        print(f\"loss: \", loss)\n",
    "        print(f\"first_order_grads: \", first_order_grads)\n",
    "        print(f\"grad_l2_norm:: \", grad_l2_norm)\n",
    "        print(f\"sensitivity_vec: \", sensitivity_vec)\n",
    "        print(f\"sensitivies: \", s)\n",
    "    '''\n",
    "\n",
    "    loss.backward()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model, calculating immediate sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "Max sensitivity for the epoch: 0.39192822575569153\n",
      "Mean sensitivity for the epoch: 0.0006331584158989662\n",
      "Accuracy: 0.7574337427278603\n",
      "Start of epoch 1\n",
      "Max sensitivity for the epoch: 0.0\n",
      "Mean sensitivity for the epoch: 0.0\n",
      "Accuracy: 0.7574337427278603\n",
      "Start of epoch 2\n",
      "Max sensitivity for the epoch: 0.0\n",
      "Mean sensitivity for the epoch: 0.0\n",
      "Accuracy: 0.7574337427278603\n",
      "Start of epoch 3\n",
      "Max sensitivity for the epoch: 0.0\n",
      "Mean sensitivity for the epoch: 0.0\n",
      "Accuracy: 0.7574337427278603\n",
      "Start of epoch 4\n",
      "Max sensitivity for the epoch: 0.0\n",
      "Mean sensitivity for the epoch: 0.0\n",
      "Accuracy: 0.7574337427278603\n",
      "Start of epoch 5\n",
      "Max sensitivity for the epoch: 0.0\n",
      "Mean sensitivity for the epoch: 0.0\n",
      "Accuracy: 0.7574337427278603\n",
      "Start of epoch 6\n",
      "Max sensitivity for the epoch: 0.0\n",
      "Mean sensitivity for the epoch: 0.0\n",
      "Accuracy: 0.7574337427278603\n",
      "Start of epoch 7\n",
      "Max sensitivity for the epoch: 0.0\n",
      "Mean sensitivity for the epoch: 0.0\n",
      "Accuracy: 0.7574337427278603\n",
      "Start of epoch 8\n",
      "Max sensitivity for the epoch: 0.0\n",
      "Mean sensitivity for the epoch: 0.0\n",
      "Accuracy: 0.7574337427278603\n",
      "Start of epoch 9\n",
      "Max sensitivity for the epoch: 0.0\n",
      "Mean sensitivity for the epoch: 0.0\n",
      "Accuracy: 0.7574337427278603\n",
      "Done training\n"
     ]
    }
   ],
   "source": [
    "# reset the model\n",
    "model = Classifier(n_features=n_features)\n",
    "model_criterion = nn.BCELoss()\n",
    "model_optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "# number of epochs and iterations\n",
    "epochs = 10\n",
    "iters = epochs * len(train_loader)\n",
    "\n",
    "# parameters for Renyi differential privacy\n",
    "alpha = 10\n",
    "epsilon = 4.0\n",
    "epsilon_iter = epsilon / iters\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "    all_sensitivities = []\n",
    "    \n",
    "    for x_batch_train, y_batch_train in train_loader:\n",
    "        model_optimizer.zero_grad()\n",
    "        batch_sensitivities = grad_immediate_sensitivity(model, model_criterion, x_batch_train, y_batch_train,epoch)\n",
    "        \n",
    "        all_sensitivities.extend(batch_sensitivities)\n",
    "        batch_sensitivity = np.max(batch_sensitivities)\n",
    "        \n",
    "        # this is the scale of the Gaussian noise to be added to the sum of gradients for the batch\n",
    "        sigma_squared_sum = (batch_sensitivity**2 * alpha) / (2 * epsilon_iter)\n",
    "        \n",
    "        # this is the scale of the Gaussian noise to be added to the average of the gradients\n",
    "        sigma_squared_avg = sigma_squared_sum / len(x_batch_train)\n",
    "        \n",
    "        # print('Please add Gaussian noise with sigma^2 =', sigma_squared_avg)\n",
    "        for p in model.parameters():\n",
    "            p.grad += (sigma_squared_avg)  # or whatever other operation\n",
    "        \n",
    "        model_optimizer.step()\n",
    "\n",
    "    print(\"Max sensitivity for the epoch:\", np.max(all_sensitivities))\n",
    "    print(\"Mean sensitivity for the epoch:\", np.mean(all_sensitivities))\n",
    "    print(\"Accuracy:\", accuracy(model, test_loader))\n",
    "\n",
    "    \n",
    "print('Done training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous Model Training Code Without Adding Noise For Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "Max sensitivity for the epoch: 9.882757186889648\n",
      "Mean sensitivity for the epoch: 0.21665751224502275\n",
      "Accuracy: 0.7878151260504201\n",
      "Start of epoch 1\n",
      "Max sensitivity for the epoch: 19.95151138305664\n",
      "Mean sensitivity for the epoch: 0.5091695647716462\n",
      "Accuracy: 0.8075307045895281\n",
      "Start of epoch 2\n",
      "Max sensitivity for the epoch: 32.361202239990234\n",
      "Mean sensitivity for the epoch: 0.6698924439514002\n",
      "Accuracy: 0.8201357466063348\n",
      "Start of epoch 3\n",
      "Max sensitivity for the epoch: 45.165550231933594\n",
      "Mean sensitivity for the epoch: 0.7987026656572642\n",
      "Accuracy: 0.8236910148674854\n",
      "Start of epoch 4\n",
      "Max sensitivity for the epoch: 67.7490463256836\n",
      "Mean sensitivity for the epoch: 0.8200503147640409\n",
      "Accuracy: 0.8240142210730446\n",
      "Start of epoch 5\n",
      "Max sensitivity for the epoch: 67.6839370727539\n",
      "Mean sensitivity for the epoch: 0.8216344941080961\n",
      "Accuracy: 0.8295087265675501\n",
      "Start of epoch 6\n",
      "Max sensitivity for the epoch: 56.20759963989258\n",
      "Mean sensitivity for the epoch: 0.8645697086624091\n",
      "Accuracy: 0.8290239172592114\n",
      "Start of epoch 7\n",
      "Max sensitivity for the epoch: 88.70437622070312\n",
      "Mean sensitivity for the epoch: 0.916916074175275\n",
      "Accuracy: 0.8309631544925663\n",
      "Start of epoch 8\n",
      "Max sensitivity for the epoch: 64.8629379272461\n",
      "Mean sensitivity for the epoch: 0.819637647034615\n",
      "Accuracy: 0.827246283128636\n",
      "Start of epoch 9\n",
      "Max sensitivity for the epoch: 68.29400634765625\n",
      "Mean sensitivity for the epoch: 0.8411223606732328\n",
      "Accuracy: 0.8206205559146735\n",
      "Start of epoch 10\n",
      "Max sensitivity for the epoch: 80.29093933105469\n",
      "Mean sensitivity for the epoch: 0.862753524712186\n",
      "Accuracy: 0.8206205559146735\n",
      "Start of epoch 11\n",
      "Max sensitivity for the epoch: 82.70394134521484\n",
      "Mean sensitivity for the epoch: 0.8516097380508458\n",
      "Accuracy: 0.8285391079508727\n",
      "Start of epoch 12\n",
      "Max sensitivity for the epoch: 133.50193786621094\n",
      "Mean sensitivity for the epoch: 0.8662898245452981\n",
      "Accuracy: 0.8275694893341952\n",
      "Start of epoch 13\n",
      "Max sensitivity for the epoch: 148.27943420410156\n",
      "Mean sensitivity for the epoch: 0.9519477249509787\n",
      "Accuracy: 0.8293471234647706\n",
      "Start of epoch 14\n",
      "Max sensitivity for the epoch: 159.86854553222656\n",
      "Mean sensitivity for the epoch: 0.9169368550883219\n",
      "Accuracy: 0.8288623141564319\n",
      "Start of epoch 15\n",
      "Max sensitivity for the epoch: 102.22904968261719\n",
      "Mean sensitivity for the epoch: 0.8488372991640621\n",
      "Accuracy: 0.8356496444731739\n",
      "Start of epoch 16\n",
      "Max sensitivity for the epoch: 263.5013427734375\n",
      "Mean sensitivity for the epoch: 0.7701869571872262\n",
      "Accuracy: 0.8356496444731739\n",
      "Start of epoch 17\n",
      "Max sensitivity for the epoch: 93.39891815185547\n",
      "Mean sensitivity for the epoch: 0.8551456973229188\n",
      "Accuracy: 0.8288623141564319\n",
      "Start of epoch 18\n",
      "Max sensitivity for the epoch: 120.6263656616211\n",
      "Mean sensitivity for the epoch: 0.9510999542393092\n",
      "Accuracy: 0.834841628959276\n",
      "Start of epoch 19\n",
      "Max sensitivity for the epoch: 58.58182907104492\n",
      "Mean sensitivity for the epoch: 0.83956036672546\n",
      "Accuracy: 0.8320943762120233\n",
      "Done training\n"
     ]
    }
   ],
   "source": [
    "# reset the model\n",
    "model = Classifier(n_features=n_features)\n",
    "model_criterion = nn.BCELoss()\n",
    "model_optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "# number of epochs and iterations\n",
    "epochs = 20\n",
    "iters = epochs * len(train_loader)\n",
    "\n",
    "# parameters for Renyi differential privacy\n",
    "alpha = 10\n",
    "epsilon = 4.0\n",
    "epsilon_iter = epsilon / iters\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "    all_sensitivities = []\n",
    "    \n",
    "    for x_batch_train, y_batch_train in train_loader:\n",
    "        model_optimizer.zero_grad()\n",
    "        batch_sensitivities = grad_immediate_sensitivity(model, model_criterion, x_batch_train, y_batch_train)\n",
    "        \n",
    "        all_sensitivities.extend(batch_sensitivities)\n",
    "        batch_sensitivity = np.max(batch_sensitivities)\n",
    "        \n",
    "        # this is the scale of the Gaussian noise to be added to the sum of gradients for the batch\n",
    "        sigma_squared_sum = (batch_sensitivity**2 * alpha) / (2 * epsilon_iter)\n",
    "        \n",
    "        # this is the scale of the Gaussian noise to be added to the average of the gradients\n",
    "        sigma_squared_avg = sigma_squared_sum / len(x_batch_train)\n",
    "        \n",
    "        # print('Please add Gaussian noise with sigma^2 =', sigma_squared_avg)\n",
    "        \n",
    "        model_optimizer.step()\n",
    "\n",
    "    print(\"Max sensitivity for the epoch:\", np.max(all_sensitivities))\n",
    "    print(\"Mean sensitivity for the epoch:\", np.mean(all_sensitivities))\n",
    "    print(\"Accuracy:\", accuracy(model, test_loader))\n",
    "\n",
    "    \n",
    "print('Done training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Adult_Dataset_Smoothed_Prediction_Sensitivity.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
