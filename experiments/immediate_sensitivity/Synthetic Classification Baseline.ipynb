{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from IPython import display\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "import sklearn.datasets\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(7)\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\n",
    "\n",
    "%matplotlib inline\n",
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "\n",
    "X, y = sklearn.datasets.make_classification(n_samples=1000,\n",
    "                                            n_features=10,\n",
    "                                            n_informative=5,\n",
    "                                            n_redundant=2,\n",
    "                                            n_repeated=0,\n",
    "                                            class_sep=0.5,\n",
    "                                            n_classes=n_classes,\n",
    "                                            random_state = 4)\n",
    "\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 800\n",
      "len test: 200\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "print('len train:', len(X_train))\n",
    "print('len test:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "training_dataset = TensorDataset(torch.from_numpy(X_train).float(), \n",
    "                                 torch.from_numpy(y_train).long())\n",
    "train_loader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "testing_dataset = TensorDataset(torch.from_numpy(X_test).float(), \n",
    "                                torch.from_numpy(y_test).long())\n",
    "test_loader = DataLoader(testing_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=256):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_classes),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, X, y):\n",
    "    Xt = torch.from_numpy(X).float()\n",
    "    yt = torch.from_numpy(y).long()\n",
    "    outputs = model(Xt)\n",
    "    values, indices = outputs.max(dim=1)\n",
    "    y_hat = indices.detach().numpy()\n",
    "    accuracy = np.sum(y_hat == y) / len(y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd_hacks\n",
    "import immediate_sensitivity_primitives as isp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps(epsilon, alpha, delta):\n",
    "    ed_eps = epsilon + np.log(1/delta)/(alpha - 1)\n",
    "    print(f'Total epsilon = {ed_eps}, delta = {delta}')\n",
    "    return ed_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(epsilon, epochs, add_noise=False):\n",
    "    # reset the model\n",
    "    model = Classifier(n_features=n_features)\n",
    "    model_criterion = nn.NLLLoss() \n",
    "    model_optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "    autograd_hacks.add_hooks(model)\n",
    "\n",
    "    alpha = 200\n",
    "    C = 5\n",
    "    epsilon_iter = epsilon / epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch_train, y_batch_train in train_loader:\n",
    "            model_optimizer.zero_grad()\n",
    "            inp = Variable(x_batch_train, requires_grad=True)\n",
    "            outputs = model.forward(inp)\n",
    "            loss = model_criterion(outputs, y_batch_train)\n",
    "            loss.backward()\n",
    "            autograd_hacks.compute_grad1(model)\n",
    "            mn = isp.clipped_autograd(model, C)\n",
    "            autograd_hacks.clear_backprops(model)\n",
    "            \n",
    "            if add_noise:\n",
    "                sigma_sq = np.sqrt(((C/BATCH_SIZE)**2 * alpha) / (2 * epsilon_iter))\n",
    "                sigma = np.sqrt(sigma_sq)\n",
    "                #print(sigma)\n",
    "                with torch.no_grad():\n",
    "                    for p in model.parameters():\n",
    "                        p.grad += (sigma * torch.randn(1).float())\n",
    "\n",
    "            model_optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.505"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = run_experiment(1, 10, True)\n",
    "accuracy(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_experiment(epsilon):\n",
    "    model = run_experiment(epsilon, 10, True)\n",
    "    return accuracy(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments():\n",
    "    epsilons = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    runs = 10\n",
    "    alpha = 200\n",
    "    results = {}\n",
    "    \n",
    "    for eps in epsilons:\n",
    "        ed_eps = get_eps(eps, 200, 1e-5)\n",
    "        results[ed_eps] = [one_experiment(eps) for _ in range(runs)]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epsilon = 0.06785389680889561, delta = 1e-05\n",
      "Total epsilon = 0.1578538968088956, delta = 1e-05\n",
      "Total epsilon = 1.0578538968088955, delta = 1e-05\n",
      "Total epsilon = 10.057853896808895, delta = 1e-05\n",
      "Total epsilon = 100.0578538968089, delta = 1e-05\n"
     ]
    }
   ],
   "source": [
    "all_results = run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_epsilons = [0.06785389680889561, 0.1578538968088956, 1.0578538968088955, 10.057853896808895, 100.0578538968089]\n",
      "baseline_means = [0.472, 0.5055, 0.49400000000000005, 0.522, 0.726]\n",
      "baseline_stds = [0.021000000000000005, 0.07538070044779366, 0.032, 0.0987977732542591, 0.159245094115957]\n"
     ]
    }
   ],
   "source": [
    "print(f'{setting}_epsilons = {list(all_results.keys())}')\n",
    "print(f'{setting}_means = {[np.mean(vs) for vs in all_results.values()]}')\n",
    "print(f'{setting}_stds = {[np.std(vs) for vs in all_results.values()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
