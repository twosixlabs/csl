{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from IPython import display\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import yappi\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(7)\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\n",
    "\n",
    "%matplotlib inline\n",
    "print(torch.__version__) \n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility for loading up the dataset\n",
    "\n",
    "def load_adult_data(path):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "                    'martial_status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                    'capital_gain', 'capital_loss', 'hours_per_week', 'country', 'target']\n",
    "    input_data = (pd.read_csv(path, names=column_names,\n",
    "                              na_values=\"?\", sep=r'\\s*,\\s*', engine='python')\n",
    "                  .loc[lambda df: df['race'].isin(['White', 'Black'])])\n",
    "\n",
    "    # targets; 1 when someone makes over 50k , otherwise 0\n",
    "    y = (input_data['target'] == '>50K').astype(int)\n",
    "\n",
    "    # features; note that the 'target' and sentive attribute columns are dropped\n",
    "    X = (input_data\n",
    "         .drop(columns=['target', 'fnlwgt'])\n",
    "         .fillna('Unknown')\n",
    "         .pipe(pd.get_dummies, drop_first=True))\n",
    "\n",
    "    y = y.to_frame()\n",
    "    for col in X.columns:\n",
    "        X[col] = X[col].astype('float32')\n",
    "\n",
    "    for col in y.columns:\n",
    "        y[col] = y[col].astype('float32')\n",
    "\n",
    "    print(f\"features X: {X.shape[0]} samples, {X.shape[1]} attributes\")\n",
    "    print(f\"targets y: {y.shape} samples\")\n",
    "    return X, y\n",
    "\n",
    "class PandasDataSet(TensorDataset):\n",
    "    def __init__(self, *dataframes):\n",
    "        tensors = (self._df_to_tensor(df) for df in dataframes)\n",
    "        super(PandasDataSet, self).__init__(*tensors)\n",
    "\n",
    "    def _df_to_tensor(self, df):\n",
    "        if isinstance(df, pd.Series):\n",
    "            df = df.to_frame('dummy')\n",
    "        return torch.from_numpy(df.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features X: 30940 samples, 95 attributes\n",
      "targets y: (30940, 1) samples\n",
      "        age  education_num  capital_gain  capital_loss  hours_per_week  \\\n",
      "27719  17.0            7.0           0.0           0.0            12.0   \n",
      "936    47.0           14.0           0.0           0.0            25.0   \n",
      "3936   46.0           11.0           0.0           0.0            38.0   \n",
      "8500   45.0           14.0           0.0        1902.0            50.0   \n",
      "3882   51.0           10.0           0.0           0.0            40.0   \n",
      "\n",
      "       workclass_Local-gov  workclass_Never-worked  workclass_Private  \\\n",
      "27719                  0.0                     0.0                1.0   \n",
      "936                    0.0                     0.0                1.0   \n",
      "3936                   0.0                     0.0                0.0   \n",
      "8500                   0.0                     0.0                1.0   \n",
      "3882                   0.0                     0.0                1.0   \n",
      "\n",
      "       workclass_Self-emp-inc  workclass_Self-emp-not-inc  ...  \\\n",
      "27719                     0.0                         0.0  ...   \n",
      "936                       0.0                         0.0  ...   \n",
      "3936                      0.0                         0.0  ...   \n",
      "8500                      0.0                         0.0  ...   \n",
      "3882                      0.0                         0.0  ...   \n",
      "\n",
      "       country_Puerto-Rico  country_Scotland  country_South  country_Taiwan  \\\n",
      "27719                  0.0               0.0            0.0             0.0   \n",
      "936                    0.0               0.0            0.0             0.0   \n",
      "3936                   0.0               0.0            0.0             0.0   \n",
      "8500                   0.0               0.0            0.0             0.0   \n",
      "3882                   0.0               0.0            0.0             0.0   \n",
      "\n",
      "       country_Thailand  country_Trinadad&Tobago  country_United-States  \\\n",
      "27719               0.0                      0.0                    1.0   \n",
      "936                 0.0                      0.0                    1.0   \n",
      "3936                0.0                      0.0                    1.0   \n",
      "8500                0.0                      0.0                    1.0   \n",
      "3882                0.0                      0.0                    1.0   \n",
      "\n",
      "       country_Unknown  country_Vietnam  country_Yugoslavia  \n",
      "27719              0.0              0.0                 0.0  \n",
      "936                0.0              0.0                 0.0  \n",
      "3936               0.0              0.0                 0.0  \n",
      "8500               0.0              0.0                 0.0  \n",
      "3882               0.0              0.0                 0.0  \n",
      "\n",
      "[5 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "# load adult data set\n",
    "path = 'adult.data'\n",
    "# path = 'adult.data'\n",
    "X, y = load_adult_data(path)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# split into train/test set\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, stratify=y, random_state=7)\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training samples: 24752\n",
      "# testing samples: 6188\n",
      "# batches: 247\n",
      "# training samples: 6188\n",
      "# batches: 61\n"
     ]
    }
   ],
   "source": [
    "# Set up training & testing data\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data = PandasDataSet(X_train, y_train)\n",
    "test_data = PandasDataSet(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "print('# training samples:', len(train_data))\n",
    "print('# testing samples:', len(test_data))\n",
    "print('# batches:', len(train_loader))\n",
    "\n",
    "print('# training samples:', len(test_data))\n",
    "print('# batches:', len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, test_loader):\n",
    "    correct = 0\n",
    "\n",
    "    for examples, labels in test_loader:\n",
    "        output = model.forward(examples)\n",
    "        batch_correct = torch.sum(torch.abs(output - labels) < 0.5)\n",
    "        correct += batch_correct\n",
    "\n",
    "    acc = float(correct)/len(test_data)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=32, p_dropout=0.2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.network(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten and reconstruct network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(grads):\n",
    "    shapes = [g.shape for g in grads]\n",
    "    flats = [x.view(-1) for x in grads]\n",
    "    lens = [len(f) for f in flats]\n",
    "    view = torch.cat(flats)\n",
    "    return view, shapes, lens\n",
    "\n",
    "def reshape(view, shapes, lens):\n",
    "    i = 0\n",
    "    tensors = []\n",
    "    for s, l in zip(shapes, lens):\n",
    "        flat = view[i: i + l]\n",
    "        tensors.append(flat.view(s))\n",
    "        i += l\n",
    "    return tensors\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate DP Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_grad(model, loss, C):\n",
    "    # do gradient for each element in loss\n",
    "    first_order_grads = [torch.autograd.grad([l], model.parameters(), retain_graph=True, create_graph=True) for l in loss]\n",
    "    shapes = []\n",
    "    lens = []\n",
    "    views = []\n",
    "    # flatten views out per sample\n",
    "    for f in first_order_grads:\n",
    "        v, shapes, lens = flatten(f)\n",
    "        views.append(v)\n",
    "    #views = [torch.cat([x.view(-1) for x in f]) for f in first_order_grads]\n",
    "\n",
    "\n",
    "    # a norm for every sample\n",
    "    grad_l2_norms = [torch.norm(v, p = 2) for v in views]\n",
    "    \n",
    "    # divisors turned out to be recipricol multiplication\n",
    "    divisors = [C/norm.item() if norm.item() > C else 1 for norm in grad_l2_norms]\n",
    "        \n",
    "    # the part where we clip\n",
    "    clipped_grads = [v*d for v, d in zip(views, divisors)]\n",
    "    \n",
    "    # sum of gradients\n",
    "    cg_sum = torch.stack(clipped_grads, dim=0).sum(dim=0)\n",
    "    \n",
    "    # reshape per model shape\n",
    "    cgs = reshape(cg_sum, shapes, lens)\n",
    "    return cgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(epsilon):\n",
    "    # reset the model\n",
    "    torch.manual_seed(1)\n",
    "    np.random.seed(7)\n",
    "    model = Classifier(n_features=n_features)\n",
    "    # reduction = none makes sure that we get per sample loss\n",
    "    model_criterion = nn.BCELoss(reduction='none')\n",
    "    model_optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "    # number of epochs and iterations\n",
    "    epochs = 10\n",
    "    iters = epochs * BATCH_SIZE\n",
    "\n",
    "    # parameters for Renyi differential privacy\n",
    "    alpha = 2\n",
    "    epsilon_iter = epsilon / iters\n",
    "    C = 1.5\n",
    "    \n",
    "    # plotting criteria\n",
    "    train_losses = []\n",
    "    test_accs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "        for x_batch_train, y_batch_train in train_loader:\n",
    "            model_optimizer.zero_grad()\n",
    "            inp = Variable(x_batch_train, requires_grad=True)\n",
    "    \n",
    "            outputs = model.forward(inp)\n",
    "            loss = model_criterion(outputs, y_batch_train)\n",
    "            clipper = clipped_grad(model, loss, C)\n",
    "            # we have to average the losses because they are per sample now\n",
    "            mean_loss = loss.mean()\n",
    "            mean_loss.backward()\n",
    "            train_losses.append(mean_loss) \n",
    "\n",
    "            # this is the scale of the Gaussian noise to be added to the batch gradient\n",
    "            sigma = np.sqrt((C**2 * alpha) / (2 * epsilon_iter))\n",
    "\n",
    "            count = 0\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p.grad = clipper[count] + (sigma * torch.randn(1))\n",
    "                    count += 1\n",
    "\n",
    "            model_optimizer.step()\n",
    "\n",
    "\n",
    "        test_accs.append(accuracy(model, test_loader))\n",
    "        print(\"Accuracy:\", test_accs[-1])\n",
    "    return accuracy(model, test_loader), (train_losses, test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "Accuracy: 0.7514544279250162\n",
      "Start of epoch 1\n",
      "Accuracy: 0.7571105365223012\n",
      "Start of epoch 2\n",
      "Accuracy: 0.7512928248222366\n",
      "Start of epoch 3\n"
     ]
    }
   ],
   "source": [
    "epsilons = [0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "yappi.set_clock_type(\"cpu\")  # Use set_clock_type(\"wall\") for wall time\n",
    "yappi.start()\n",
    "experiment_results = [run_experiment(epsilon)[0] for epsilon in epsilons]\n",
    "yappi.get_func_stats().print_all()\n",
    "yappi.get_thread_stats().print_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epsilons, experiment_results)\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
