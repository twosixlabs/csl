{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.1.post3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from IPython import display\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "import sklearn.datasets\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(7)\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\n",
    "\n",
    "%matplotlib inline\n",
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "\n",
    "X, y = sklearn.datasets.make_classification(n_samples=1000,\n",
    "                                            n_features=5,\n",
    "                                            n_informative=5,\n",
    "                                            n_redundant=0,\n",
    "                                            n_repeated=0,\n",
    "                                            class_sep=.5,\n",
    "                                            n_classes=n_classes,\n",
    "                                            random_state = 4)\n",
    "\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 800\n",
      "len test: 200\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "print('len train:', len(X_train))\n",
    "print('len test:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "training_dataset = TensorDataset(torch.from_numpy(X_train).float(), \n",
    "                                 torch.from_numpy(y_train).long())\n",
    "train_loader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "testing_dataset = TensorDataset(torch.from_numpy(X_test).float(), \n",
    "                                torch.from_numpy(y_test).long())\n",
    "test_loader = DataLoader(testing_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=6):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "#            nn.ReLU(),\n",
    "#            nn.Linear(n_hidden, n_hidden),\n",
    "#            nn.ReLU(),\n",
    "#            nn.Linear(n_hidden, n_hidden),\n",
    "#            nn.ReLU(),\n",
    "#            nn.Linear(n_hidden, n_hidden),\n",
    "#            nn.ReLU(),\n",
    "#            nn.Linear(n_hidden, n_classes),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=6):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_classes),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, X, y):\n",
    "    Xt = torch.from_numpy(X).float()\n",
    "    yt = torch.from_numpy(y).long()\n",
    "    outputs = model(Xt)\n",
    "    values, indices = outputs.max(dim=1)\n",
    "    y_hat = indices.detach().numpy()\n",
    "    accuracy = np.sum(y_hat == y) / len(y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd_hacks\n",
    "import immediate_sensitivity_primitives as isp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps(epsilon, alpha, delta):\n",
    "    ed_eps = epsilon + np.log(1/delta)/(alpha - 1)\n",
    "    print(f'Total epsilon = {ed_eps}, delta = {delta}')\n",
    "    return ed_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epsilon = 0.03623026311456169, delta = 1e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03623026311456169"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eps(0.036, 50000, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad_median(model, C):\n",
    "    for param in model.parameters():\n",
    "        median_grad = param.grad1.data.median(axis=0).values\n",
    "        param.grad = median_grad\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad_trimmed_mean(model, C):\n",
    "    for param in model.parameters():\n",
    "        agg_grad = param.grad1.data.clamp(min=-.1, max=.1).mean(axis=0)\n",
    "        param.grad = agg_grad\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sens(xs, n, m, a, b):\n",
    "    def get(i):\n",
    "        if i < 0:\n",
    "            return a\n",
    "        elif i >= n:\n",
    "            return b\n",
    "        else:\n",
    "            return xs[i]\n",
    "    \n",
    "    # calculate the smooth sensitivity\n",
    "    t = 1\n",
    "    scaled_sensitivity_at_distances = []\n",
    "\n",
    "    for k in range(0, n+1):\n",
    "        scaling = np.exp(- k * t)\n",
    "        \n",
    "        indices = [(n-m+1+k-l, m+1-l) for l in range(0, k+1)]\n",
    "        inner_max = torch.tensor([get(n-m+1+k-l) - get(m+1-l) for l in range(0, k+2)]).max()\n",
    "        scaled_inner = scaling * inner_max\n",
    "        scaled_sensitivity_at_distances.append(scaled_inner)\n",
    "\n",
    "    return (1/(n - 2*m)) * np.max(scaled_sensitivity_at_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad_trimmed_mean(model, C):\n",
    "    sensitivities = []\n",
    "    for param in model.parameters():\n",
    "        clipped_grads = param.grad1.data.clamp(min=-1, max=1)\n",
    "        sorted_grad = clipped_grads.sort(axis=0).values\n",
    "        \n",
    "        # calculate m\n",
    "        n = BATCH_SIZE\n",
    "        #m = int((2*n - n) / 4) # define m to include 50% of the data\n",
    "        m = int((4*n - n) / 8) # define m to include 25% of the data\n",
    "        m = int((9/20)*n)\n",
    "        \n",
    "        # aggregate the gradients (perform the trimmed mean)\n",
    "        trimmed_grads = sorted_grad[m+1:n-m]\n",
    "        agg_grad = trimmed_grads.mean(axis=0)\n",
    "        agg_grad = clipped_grads.mean(axis=0)\n",
    "        param.grad = agg_grad\n",
    "        \n",
    "        #print('sorted grad shape:', sorted_grad.shape)\n",
    "        #print(sorted_grad[:,0,0].shape)\n",
    "        #print(sorted_grad)\n",
    "        \n",
    "        reshaped = sorted_grad.reshape((n, -1))\n",
    "        bs, w = reshaped.shape\n",
    "        \n",
    "        for i in range(w):\n",
    "            sensitivities.append(compute_sens(reshaped[:, i], n, m, -.1, .1))\n",
    "        \n",
    "    #print(sensitivities)\n",
    "    return sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(epsilon, epochs, add_noise=False):\n",
    "    # reset the model\n",
    "    model = Classifier(n_features=n_features)\n",
    "    model_criterion = nn.NLLLoss() \n",
    "    model_optimizer = optim.Adam(model.parameters(),lr=0.1)\n",
    "    autograd_hacks.add_hooks(model)\n",
    "\n",
    "    info = {\n",
    "        'sensitivities': [],\n",
    "        'epsilons': [],\n",
    "        'total_epsilon': []\n",
    "    }\n",
    "\n",
    "    sigma_sq = 0.01\n",
    "    t = 1\n",
    "    alpha = 5000\n",
    "    gamma = alpha*(np.exp(t) - 1) + 1\n",
    "\n",
    "    def compute_eps_bar(sens):\n",
    "        return alpha * ((sens**2 / (2*gamma*sigma_sq)) + (t**2 / (4*gamma**2)))\n",
    "\n",
    "    total_epsilon = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_epsilons = []\n",
    "        for x_batch_train, y_batch_train in train_loader:\n",
    "            model_optimizer.zero_grad()\n",
    "            inp = Variable(x_batch_train, requires_grad=True)\n",
    "            outputs = model.forward(inp)\n",
    "            loss = model_criterion(outputs, y_batch_train)\n",
    "            loss.backward()\n",
    "            autograd_hacks.compute_grad1(model)\n",
    "            sensitivities = compute_grad_trimmed_mean(model, None)\n",
    "            batch_sens = np.linalg.norm(sensitivities, ord=2)\n",
    "\n",
    "            info['sensitivities'].append(batch_sens)\n",
    "\n",
    "            autograd_hacks.clear_backprops(model)\n",
    "\n",
    "            eps_iter = compute_eps_bar(batch_sens)\n",
    "            epoch_epsilons.append(eps_iter)\n",
    "            info['epsilons'].append(eps_iter)\n",
    "            \n",
    "            if add_noise:\n",
    "                #sigma_sq = np.sqrt(((batch_sens)**2 * alpha) / (2 * epsilon_iter))\n",
    "                sigma = np.sqrt(sigma_sq)\n",
    "                #print(sigma)\n",
    "                with torch.no_grad():\n",
    "                    for p in model.parameters():\n",
    "                        p.grad += (sigma * torch.randn(p.shape).float())\n",
    "\n",
    "            model_optimizer.step()\n",
    "\n",
    "        #print(epoch_epsilons)\n",
    "        total_epsilon = total_epsilon + np.max(epoch_epsilons)\n",
    "        info['total_epsilon'].append(total_epsilon)\n",
    "        #print(total_epsilon)\n",
    "\n",
    "    if False:\n",
    "        plt.plot(info['sensitivities'])\n",
    "        plt.title('Smooth Sensitivity, by Iteration')\n",
    "        plt.show()\n",
    "        plt.plot(info['epsilons'])\n",
    "        plt.title('Epsilon, by Iteration')\n",
    "        plt.show()\n",
    "        plt.plot(info['total_epsilon'])\n",
    "        plt.title('Total Epsilon, by Epoch')\n",
    "        print(info['total_epsilon'])\n",
    "        plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = run_experiment(10, 5, True)\n",
    "accuracy(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epsilon = 0.006303045702134472, delta = 1e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006303045702134472"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eps(0.004, 5000, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tcdp(rho, omega, delta):\n",
    "    if np.log(1/delta) <= rho*(omega - 1)**2:\n",
    "        print('case 1')\n",
    "        return rho + 2*np.sqrt(rho*np.log(1/delta))\n",
    "    else:\n",
    "        print('case 2')\n",
    "        return rho*omega + np.log(1/delta) / (omega - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21.169565309270794"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_tcdp(1.08*5, 10, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.508331944775044"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1-np.exp(-.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_experiment(epsilon):\n",
    "    model = run_experiment(epsilon, 10, True)\n",
    "    return accuracy(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments():\n",
    "    epsilons = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    runs = 10\n",
    "    alpha = 200\n",
    "    results = {}\n",
    "    \n",
    "    for eps in epsilons:\n",
    "        ed_eps = get_eps(eps, 200, 1e-5)\n",
    "        results[ed_eps] = [one_experiment(eps) for _ in range(runs)]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total epsilon = 0.06785389680889561, delta = 1e-05\n",
      "Total epsilon = 0.1578538968088956, delta = 1e-05\n",
      "Total epsilon = 1.0578538968088955, delta = 1e-05\n",
      "Total epsilon = 10.057853896808895, delta = 1e-05\n",
      "Total epsilon = 100.0578538968089, delta = 1e-05\n"
     ]
    }
   ],
   "source": [
    "all_results = run_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_epsilons = [0.06785389680889561, 0.1578538968088956, 1.0578538968088955, 10.057853896808895, 100.0578538968089]\n",
      "baseline_means = [0.472, 0.5055, 0.49400000000000005, 0.522, 0.726]\n",
      "baseline_stds = [0.021000000000000005, 0.07538070044779366, 0.032, 0.0987977732542591, 0.159245094115957]\n"
     ]
    }
   ],
   "source": [
    "print(f'{setting}_epsilons = {list(all_results.keys())}')\n",
    "print(f'{setting}_means = {[np.mean(vs) for vs in all_results.values()]}')\n",
    "print(f'{setting}_stds = {[np.std(vs) for vs in all_results.values()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
