{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11783 5050\n",
      "Epoch 0: train loss 4.143445014953613, test loss 3.7030820846557617, adv 0.022762506967670015, acc 0.16806891025641027\n",
      "Epoch 1: train loss 2.980689764022827, test loss 2.5911831855773926, adv 0.058517541109253, acc 0.36999198717948717\n",
      "Epoch 2: train loss 2.0997700691223145, test loss 2.091527223587036, adv 0.0868520066889632, acc 0.4443108974358974\n",
      "Epoch 3: train loss 1.6351245641708374, test loss 1.868760108947754, adv 0.1125104515050167, acc 0.48818108974358976\n",
      "Epoch 4: train loss 1.3511989116668701, test loss 1.7969446182250977, adv 0.13864792363433676, acc 0.5130208333333334\n",
      "Epoch 5: train loss 1.1503796577453613, test loss 1.7155781984329224, adv 0.17653898411371238, acc 0.5300480769230769\n",
      "Epoch 6: train loss 0.9886560440063477, test loss 1.7079403400421143, adv 0.21239417851170567, acc 0.5248397435897436\n",
      "Epoch 7: train loss 0.8645074367523193, test loss 1.73690664768219, adv 0.2334408967391305, acc 0.5322516025641025\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import experiment_runner as er\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = pickle.load(open(\"../../inputs/texas_100_features.p\", 'rb')).astype(np.float32)\n",
    "labels = pickle.load(open(\"../../inputs/texas_100_labels.p\", 'rb'))\n",
    "\n",
    "ds = list(zip(features, labels))\n",
    "\n",
    "_, ds = train_test_split(ds, shuffle=True)\n",
    "\n",
    "texas_train, texas_test = train_test_split(ds, test_size=.3, shuffle=True)\n",
    "print(len(texas_train), len(texas_test))\n",
    "\n",
    "\n",
    "class Texas_Classifier(nn.Module):\n",
    "    def __init__(self, w):\n",
    "        super(Texas_Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(6169, w)\n",
    "        self.fc2 = nn.Linear(w, w)\n",
    "        self.fc3 = nn.Linear(w, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc3(x)\n",
    "        return torch.log_softmax(x,dim=1)\n",
    "    \n",
    "    \n",
    "\n",
    "model = Texas_Classifier(128)\n",
    "info, model = er.run_experiment(model,\n",
    "                                texas_train,\n",
    "                                texas_test,\n",
    "                                epsilon=0,\n",
    "                                alpha=2,\n",
    "                                epochs=8,\n",
    "                                add_noise=False,\n",
    "                                throw_out_threshold=False,\n",
    "                                throw_out_std=0,\n",
    "                                batch_size=64,\n",
    "                                lf=torch.nn.NLLLoss,\n",
    "                                print_rate=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import membership_inference as mi\n",
    "train_loader = torch.utils.data.DataLoader(texas_train, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(texas_test, batch_size=64, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07994237924905663\n",
      "0.3729967948717949 0.1308963907469342\n",
      "0.03575131885679184\n",
      "0.47836538461538464 0.20172493380713497\n",
      "0.02528\n",
      "0.5172275641025641 0.2160304312987737\n",
      "0.01787565942839592\n",
      "0.5190304487179487 0.22526041666666669\n",
      "0.015988475849811327\n",
      "0.5152243589743589 0.22356857929208473\n",
      "0.011305559694238937\n",
      "0.5230368589743589 0.22898158793199552\n",
      "0.009230950835820399\n",
      "0.5292467948717948 0.23430314590301\n",
      "0.007994237924905664\n",
      "0.5262419871794872 0.22940835772017842\n"
     ]
    }
   ],
   "source": [
    "sens = .001 * 3.16 * 8 # lr * constant term * num epochs\n",
    "alpha = 20\n",
    "epsilon = 25\n",
    "for e in [1, 5, 10, 20, 25, 50, 75, 100]:\n",
    "    m1 = deepcopy(model)\n",
    "    sigma = np.sqrt((sens**2 * alpha) / (2 * e))\n",
    "    print(sigma)\n",
    "    with torch.no_grad():\n",
    "        for p in m1.parameters():\n",
    "            p += (sigma * torch.randn(p.shape,device=torch.cuda.current_device()).float())\n",
    "\n",
    "        \n",
    "    avg_test_acc, avg_test_l = er.loader_accuracy(m1, test_loader, lf=torch.nn.NLLLoss())\n",
    "    avg_train_l = 0.8645074367523193\n",
    "            \n",
    "    tpr = mi.run_yeom_loader(m1, avg_train_l, train_loader, lf=torch.nn.NLLLoss)\n",
    "    fpr = mi.run_yeom_loader(m1, avg_train_l, test_loader, lf=torch.nn.NLLLoss)\n",
    "    adv = tpr-fpr\n",
    "    print(avg_test_acc, adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
