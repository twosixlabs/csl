{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUNS ON GRID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 03. Synthetic Dataset Generators Trainined using Differential Privacy and Immediate Sensitivity\n",
    "\n",
    "This example notebook is intended to serve as a guide for csl data synthesis module and its associated methods.\n",
    "\n",
    "**CSL Modules:**\n",
    "* `synthesizers`   <--   **_main focus_**\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**This notebook:** \n",
    "\n",
    "Focuses on the `synthesizers` module and its convenience methods, which include:\n",
    "\n",
    "A. Differential privacy parameters: `ALPHA` and `EPSILON` for imnmediate sensitivity\n",
    "\n",
    "B. `train_and_synthesize`: train a model and use the checkpoint to synthesize train data\n",
    "\n",
    "C. `synthesize_using_pretrained`: load an existing (pre-trained) model and use it to synthesize validation data\n",
    "\n",
    "**Note:**\n",
    "The argument `tasks` (a list) can be set to process train and val sequentially (i.e., `tasks = [train, val]`) in `train_and_synthesize` to train a model and synthesize train and val datasets as a single call. The order must be preserved as val cannot be generated without a trained model.\n",
    "\n",
    "*The `synthesizers.py` module supports command line arguments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/persist/carlos_folder/csl/csl\")\n",
    "\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "\n",
    "import csl.synthesizers as syn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VARIABLES**\n",
    "* `METHOD`: str, synthesis method (architecture). Currently supported methods: vae, cvae, dcgan\n",
    "* `DATASET_NAME`: str, name of the dataset\n",
    "* `MODELS_DIR`: os.pathlike, where \" _to save_ \" and \" _load from_ \" models\n",
    "* `DATA_DIR`: os.pathlike, where to \" _to save_ \" synthesized data\n",
    "* `TASK`: list, what to synthesize train, test (for some datasets), or val\n",
    "\n",
    "*Differential Privacy Training*\n",
    "* `ALPHA`: float (default = None)\n",
    "* `EPSILON`: float (default = None)\n",
    "\n",
    "**NOTE** both `ALPHA` and `EPSILON` to be set to something other than `None` to enable differential privacy (immediate_sensitivity) training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/persist/\"\n",
    "DATA_DIR = f\"{ROOT_DIR}datasets/\"\n",
    "MODELS_DIR = f\"{ROOT_DIR}models/\"\n",
    "\n",
    "# VARS\n",
    "METHOD = \"vae\"\n",
    "DATASET_NAME = \"mnist\"\n",
    "\n",
    "TASK = [\"train\"]  # \"val\"]  # successively mimics the train and validation sets\n",
    "N_EPOCHS = 10\n",
    "NUM_WORKERS = 16\n",
    "BATCH_SIZE = 32\n",
    "CLASS_INDEX = \"all\"  # 0, 1, 2... etc\n",
    "ALPHAS = [None, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Train and synthesize\n",
    "\n",
    "Trains a new model based on the method and dataset name (i.e., input source) variables and uses the pretrained model to generate a synthetic version of the input source.\n",
    "\n",
    "\n",
    "**inputs:**\n",
    "* method: str, see METHOD\n",
    "* dataset_name: str, see DATASET_NAME\n",
    "* batch_size: int, size of the sample\n",
    "* num_workers: int, number of virtual cores to use to move data and execute non-gpu data operations\n",
    "* class_index: int (or str), \n",
    "    - int: index of the class to sample, train on, and synthesize\n",
    "    - str:= \"all\", means all classess\n",
    "* num_epochs: int, number of total passess to train over\n",
    "* image_dim: int, size of the input/outputs images (images are resized to square tiles)\n",
    "* task: list, see TASK\n",
    "* num_samples: int (or str),\n",
    "    - int: specific number of samples to synthesize (can be any positive number)\n",
    "    - str:= \"all\" looks at the source dataset for the number of sample (mimics the original input dataset label count distribution)\n",
    "* data_save_dir: os.pathlike, see DATA_DIR\n",
    "* model_save_dir: os.pathlike, see MODELS_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-30 05:35:38 53447080b262 datasets[121511] INFO Processing 'mnist' torch.vision built-in structure\n",
      "2021-01-30 05:35:38 53447080b262 datasets[121511] INFO Processing 'mnist' torch.vision built-in structure\n",
      "2021-01-30 05:35:38 53447080b262 datasets[121511] INFO  > Extracting all (max) samples for 0 class(es).\n",
      "Train Batch 1: 100%|██████████| 186/186 [00:02<00:00, 77.65it/s]\n",
      "2021-01-30 05:35:46 53447080b262 data_generators.vae.vaes[121511] INFO ====> Epoch: 1 Average Train loss:  49.8599\n",
      "2021-01-30 05:35:48 53447080b262 data_generators.vae.vaes[121511] INFO ====> Test set loss:  47.2477\n",
      "\n",
      "Train Batch 2: 100%|██████████| 186/186 [00:02<00:00, 82.28it/s]\n",
      "2021-01-30 05:35:50 53447080b262 data_generators.vae.vaes[121511] INFO ====> Epoch: 2 Average Train loss:  45.6274\n",
      "2021-01-30 05:35:51 53447080b262 data_generators.vae.vaes[121511] INFO ====> Test set loss:  43.3431\n",
      "\n",
      "Train Batch 3:   0%|          | 0/186 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ===> 2-epoch. Updating best (with 43.343), which is less than previous (47.248) best_loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batch 3: 100%|██████████| 186/186 [00:02<00:00, 77.73it/s]\n",
      "2021-01-30 05:35:54 53447080b262 data_generators.vae.vaes[121511] INFO ====> Epoch: 3 Average Train loss:  41.6899\n",
      "2021-01-30 05:35:55 53447080b262 data_generators.vae.vaes[121511] INFO ====> Test set loss:  39.4953\n",
      "\n",
      "Train Batch 4:   0%|          | 0/186 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ===> 3-epoch. Updating best (with 39.495), which is less than previous (43.343) best_loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batch 4: 100%|██████████| 186/186 [00:02<00:00, 81.14it/s]\n",
      "2021-01-30 05:35:58 53447080b262 data_generators.vae.vaes[121511] INFO ====> Epoch: 4 Average Train loss:  38.2225\n",
      "2021-01-30 05:35:59 53447080b262 data_generators.vae.vaes[121511] INFO ====> Test set loss:  36.2385\n",
      "\n",
      "Train Batch 5:   0%|          | 0/186 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ===> 4-epoch. Updating best (with 36.239), which is less than previous (39.495) best_loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batch 5: 100%|██████████| 186/186 [00:02<00:00, 81.50it/s]\n",
      "2021-01-30 05:36:02 53447080b262 data_generators.vae.vaes[121511] INFO ====> Epoch: 5 Average Train loss:  35.1037\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b1ba0743affb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         }\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# CALL TRAIN AND SYNTHESIZE TO FIT A MODEL AND SYNTHESIZE THE TRAIN DATASET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_synthesize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \"\"\"\n",
      "\u001b[0;32m/persist/carlos_folder/csl/csl/synthesizers.py\u001b[0m in \u001b[0;36mtrain_and_synthesize\u001b[0;34m(method, dataset_name, batch_size, num_workers, class_index, num_epochs, image_dim, tasks, num_samples, data_save_dir, model_save_dir, alpha, epsilon)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 model.train(\n\u001b[1;32m    310\u001b[0m                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                     \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m                 )\n\u001b[1;32m    313\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/persist/carlos_folder/csl/csl/data_generators/vae/vaes.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, test_loader, num_epochs, alpha, epsilon)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_hist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/persist/carlos_folder/csl/csl/data_generators/vae/vaes.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, test_loader)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m                 \u001b[0;31m# data = data.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/vae/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/vae/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ALPHA in ALPHAS:\n",
    "    EPSILONS = (\n",
    "        [None]\n",
    "        if ALPHA is None\n",
    "        else [1e6, 5e5, 2e5, 1e5, 1e4, 1e3, 1e2, 10, 1, 0.1, 0.01]\n",
    "    )\n",
    "    for EPSILON in EPSILONS:\n",
    "        args = {\n",
    "            \"method\": METHOD,\n",
    "            \"dataset_name\": DATASET_NAME,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"num_workers\": NUM_WORKERS,\n",
    "            \"class_index\": CLASS_INDEX,\n",
    "            \"num_epochs\": N_EPOCHS,\n",
    "            \"image_dim\": 64,\n",
    "            \"tasks\": [\"train\"],  # , \"val\"],\n",
    "            \"num_samples\": \"all\",\n",
    "            \"data_save_dir\": DATA_DIR,\n",
    "            \"model_save_dir\": MODELS_DIR,\n",
    "            \"alpha\": ALPHA,\n",
    "            \"epsilon\": EPSILON,\n",
    "        }\n",
    "        # CALL TRAIN AND SYNTHESIZE TO FIT A MODEL AND SYNTHESIZE THE TRAIN DATASET\n",
    "        syn.train_and_synthesize(**args)\n",
    "\n",
    "        \"\"\"\n",
    "        USE THE TRAINED MODEL TO SYNTHESIZE THE VALIDATION SET\n",
    "        \"\"\"\n",
    "#         print(f\"Loading checkpoint from {model_dir}\")\n",
    "#         print(f\"Synthetic dataset destination {data_dir}\")\n",
    "#         task = \"val\"\n",
    "#         for class_index in range(10):\n",
    "#             model_path = f\"{model_dir}{class_index}/\"\n",
    "#             data_path = f\"{data_dir}{class_index}/\"\n",
    "#             args = {\n",
    "#                 \"method\": METHOD,\n",
    "#                 \"dataset_name\": DATASET_NAME,\n",
    "#                 \"num_workers\": 4,\n",
    "#                 \"class_index\": class_index,  # \"all\",\n",
    "#                 \"tasks\": [task],\n",
    "#                 \"num_samples\": \"all\",\n",
    "#                 \"data_save_dir\": data_path,\n",
    "#                 \"load_model_path\": model_path,\n",
    "#             }\n",
    "#             syn.synthesize_using_pretrained(**args)\n",
    "#     print(\n",
    "#         f\"\\n\\n===\\n{DATASET_NAME}-{METHOD} DATA GENERATION USING \"\n",
    "#         f\"{ALPHA}-alpha and {EPSILON}-epsilon IS COMPLETE\\n===\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SYNTHESIZER TRAINED AND USED TO SYNTHESIZE A TRAIN DATASET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Synthesize using pretrained\n",
    "\n",
    "Loads a pretrained model and uses it to generate a synthetic version of the input source dataset. Generates all the samples for class index 0. \n",
    "\n",
    "**inputs:**\n",
    "* method: str, see METHOD\n",
    "* dataset_name: str, see DATASET_NAME\n",
    "* num_workers: int, number of virtual cores to use to move data and execute non-gpu data operations\n",
    "* class_index: int (or str), \n",
    "    - int: index of the class to sample, train on, and synthesize\n",
    "    - str:= \"all\", means all classess\n",
    "* task: list, see TASK\n",
    "* num_samples: int (or str),\n",
    "    - int: specific number of samples to synthesize (can be any positive number)\n",
    "    - str:= \"all\" looks at the source dataset for the number of sample (mimics the original input dataset label count distribution)\n",
    "* data_save_dir: os.pathlike, see DATA_DIR\n",
    "\n",
    "**NEW INPUT**\n",
    "* **load_model_path**: os.pathlike, location where the checkpoint (pretrained model state_dictionary and associated parameters) is stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE LOOP CAN BE RUN TOGETHER WITH THE PREVIOUS\n",
    "\n",
    "task = \"val\"\n",
    "    \n",
    "for ALPHA in ALPHAS:\n",
    "    EPSILONS = (\n",
    "        [None]\n",
    "        if ALPHA is None\n",
    "        else [1e6, 5e5, 2e5, 1e5, 1e4, 1e3, 1e2, 10, 1, 0.1, 0.01]\n",
    "    )\n",
    "    for EPSILON in EPSILONS:\n",
    "        if (ALPHA is not None) and (EPSILON is not None):\n",
    "            model_dir = (\n",
    "                f\"{MODELS_DIR}{DATASET_NAME}_{METHOD}_dp_{ALPHA}a_{EPSILON}e/train/\"\n",
    "            )\n",
    "            data_dir = (\n",
    "                f\"{DATA_DIR}{DATASET_NAME}_{METHOD}_dp_{ALPHA}a_{EPSILON}e/{task}/\"\n",
    "            )\n",
    "        else:\n",
    "            model_dir = f\"{MODELS_DIR}{DATASET_NAME}_{METHOD}/train/\"\n",
    "            data_dir = f\"{DATA_DIR}{DATASET_NAME}_{METHOD}/{task}/\"\n",
    "\n",
    "        print(f\"Loading checkpoint from {model_dir}\")\n",
    "        print(f\"Synthetic dataset destination {data_dir}\")\n",
    "\n",
    "        for class_index in range(10):\n",
    "            model_path = f\"{model_dir}{class_index}/\"\n",
    "            data_path = f\"{data_dir}{class_index}/\"\n",
    "            args = {\n",
    "                \"method\": METHOD,\n",
    "                \"dataset_name\": DATASET_NAME,\n",
    "                \"num_workers\": 4,\n",
    "                \"class_index\": class_index,  # \"all\",\n",
    "                \"tasks\": [task],\n",
    "                \"num_samples\": \"all\",\n",
    "                \"data_save_dir\": data_path,\n",
    "                \"load_model_path\": model_path,\n",
    "            }\n",
    "            syn.synthesize_using_pretrained(**args)\n",
    "\n",
    "    print(\n",
    "        f\"\\n\\n===\\n{DATASET_NAME}-{METHOD} DATA GENERATION USING \"\n",
    "        f\"{ALPHA}-alpha and {EPSILON}-epsilon IS COMPLETE\\n===\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ALL DONE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
