{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiments to find a lower bound for local sensitivity\n",
    "    From this and immediate sensitivity, we can find a lower bound on smoothness\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 28, kernel_size=(5,5))\n",
    "        self.conv2 = nn.Conv2d(28, 32, kernel_size=(5,5))\n",
    "        self.fc1 = nn.Linear(32*20*20, 16)\n",
    "        self.fc2 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = x.view(-1, 32*20*20)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        return torch.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_loader_generator(dataloader):\n",
    "    '''\n",
    "    Generates a function that infinitely samples a dataloader\n",
    "    '''\n",
    "    while True:\n",
    "        for x, y in dataloader:\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_data_generator(split=\"train\", batch_size=16, download=True, shuffle=False, drop_last=True, root='./data'):\n",
    "    \"\"\"\n",
    "    Return infinite data generator and size of underlying dataset\n",
    "    \"\"\"\n",
    "    if split == \"test\":\n",
    "        dataset = datasets.MNIST(root='./data', train=False, download=download, transform=torchvision.transforms.ToTensor())\n",
    "    else:\n",
    "        dataset = datasets.MNIST(root='./data', train=True, download=download, transform=torchvision.transforms.ToTensor())\n",
    "        if split == \"train\":\n",
    "            dataset = Subset(dataset, list(range(0, 50000)))\n",
    "        elif split == \"validate\" or split == \"val\":\n",
    "            dataset = Subset(dataset, list(range(50000, 60000)))\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized split {split}. Must be one of ('train', 'val', test')\")\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "    generator = inf_loader_generator(dataloader)\n",
    "    return generator, len(dataset)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(model, inf_gen, test_steps, device=DEVICE):\n",
    "    correct = 0\n",
    "    num_data = 0\n",
    "\n",
    "    #grab a batch from the test loader\n",
    "    for j in range(test_steps):\n",
    "        examples, labels = next(inf_gen)\n",
    "        outputs = model.forward(examples.to(device))\n",
    "\n",
    "        #for each output in the batch, check if the label is correct\n",
    "        for i, output in enumerate(outputs):\n",
    "            num_data += 1\n",
    "\n",
    "            max_i = np.argmax(output.detach().cpu().numpy())\n",
    "            if max_i == labels[i]:\n",
    "                correct += 1\n",
    "\n",
    "    acc = float(correct)/num_data\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_immediate_sensitivity(model, inp, loss) -> list:\n",
    "    \"\"\"Core. Computes immediate sensitivity\"\"\"\n",
    "\n",
    "    # (1) first-order gradient (wrt parameters)\n",
    "    first_order_grads = torch.autograd.grad(\n",
    "        loss,\n",
    "        model.parameters(),\n",
    "        retain_graph=True,\n",
    "        create_graph=True,\n",
    "        # allow_unused=True\n",
    "    )\n",
    "\n",
    "    # (2) L2 norm of the gradient from (1)\n",
    "    grad_l2_norm = torch.norm(torch.cat([x.view(-1) for x in first_order_grads]), p=2)\n",
    "\n",
    "    # (3) Gradient (wrt inputs) of the L2 norm of the gradient from (2)\n",
    "    sensitivity_vec = torch.autograd.grad(grad_l2_norm, inp, retain_graph=True)[0]\n",
    "    \n",
    "    # (4) L2 norm of (3) - \"immediate sensitivity\"\n",
    "    # sensitivity = [torch.norm(v, p=2).item() for v in sensitivity_vec]\n",
    "    sensitivity = torch.norm(\n",
    "        sensitivity_vec.view(sensitivity_vec.shape[0], -1), p=2, dim=1\n",
    "    )\n",
    "    \n",
    "    return sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_immediate_sensitivity_vec(model, criterion, x, y, device=DEVICE) -> list:\n",
    "    \"\"\"Core. Computes immediate sensitivity\"\"\"\n",
    "    model.zero_grad()\n",
    "    \n",
    "    x = torch.autograd.Variable(torch.clone(x).to(device), requires_grad=True)\n",
    "    y = y.to(device)\n",
    "\n",
    "    outputs = model.forward(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    # (1) first-order gradient (wrt parameters)\n",
    "    first_order_grads = torch.autograd.grad(\n",
    "        loss,\n",
    "        model.parameters(),\n",
    "        retain_graph=True,\n",
    "        create_graph=True,\n",
    "        # allow_unused=True\n",
    "    )\n",
    "\n",
    "    # (2) L2 norm of the gradient from (1)\n",
    "    grad_l2_norm = torch.norm(torch.cat([w.view(-1) for w in first_order_grads]), p=2)\n",
    "\n",
    "    # (3) Gradient (wrt inputs) of the L2 norm of the gradient from (2)\n",
    "    sensitivity_vec = torch.autograd.grad(grad_l2_norm, x, retain_graph=True)[0]\n",
    "\n",
    "    # (4) L2 norm of (3) - \"immediate sensitivity\"\n",
    "    # sensitivity = [torch.norm(v, p=2).item() for v in sensitivity_vec]\n",
    "    sensitivity = torch.norm(\n",
    "        sensitivity_vec.view(sensitivity_vec.shape[0], -1), p=2, dim=1\n",
    "    )    \n",
    "\n",
    "    return sensitivity_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_local_sensitivity_grad(model, criterion, x, y, grad_vec, device=DEVICE) -> list:\n",
    "    \"\"\"Core. Computes immediate sensitivity\"\"\"\n",
    "    model.zero_grad()\n",
    "    \n",
    "    x = torch.autograd.Variable(torch.clone(x).to(device), requires_grad=True)\n",
    "    y = y.to(device)\n",
    "\n",
    "    outputs = model.forward(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    # (1) first-order gradient (wrt parameters)\n",
    "    first_order_grads = torch.autograd.grad(\n",
    "        loss,\n",
    "        model.parameters(),\n",
    "        retain_graph=True,\n",
    "        create_graph=True,\n",
    "        # allow_unused=True\n",
    "    )\n",
    "\n",
    "    # (2) L2 norm of the gradient from (1) minus the grad_vec term\n",
    "    diff = torch.cat([w.view(-1) for w in first_order_grads]) - grad_vec\n",
    "    grad_l2_norm = torch.norm(diff, p=2)\n",
    "\n",
    "    # (3) Gradient (wrt inputs) of the L2 norm of the gradient from (2)\n",
    "    x_sensitivity_vec = torch.autograd.grad(grad_l2_norm, x, retain_graph=True)[0]\n",
    "\n",
    "    return x_sensitivity_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vec = get_grad_vec(m.model, m.criterion, x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_vec = get_grad_vec(m.model, m.criterion, x_batch, y_batch)\n",
    "x1 = compute_local_sensitivity_grad(m.model, m.criterion, x_batch, y_batch, grad_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, device=DEVICE):\n",
    "        self.device = device\n",
    "        self.model = MnistClassifier()\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(),lr=0.001)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def train(self, epochs=20, alpha=20, epsilon=1e6, batch_size=16):\n",
    "        train_ds, train_size = mnist_data_generator(split=\"train\", batch_size=batch_size)\n",
    "        val_ds, val_size = mnist_data_generator(split=\"val\", batch_size=batch_size)\n",
    "        test_ds, test_size = mnist_data_generator(split=\"test\", batch_size=batch_size)\n",
    "        \n",
    "        self.model_steps = 0\n",
    "        self.train_losses = []\n",
    "        self.val_accs = []\n",
    "        self.times = []\n",
    "        \n",
    "        train_steps_per_epoch = train_size // batch_size\n",
    "        current_epoch = 0\n",
    "        while True:\n",
    "            if self.model_steps >= epochs * train_steps_per_epoch:\n",
    "                print(\"Finished Training\")\n",
    "                break\n",
    "            if self.model_steps % train_steps_per_epoch == 0:\n",
    "                self.batch_losses = []\n",
    "                current_epoch += 1\n",
    "                print(f\"Start of Epoch {current_epoch}\")\n",
    "                start = time.time()\n",
    "\n",
    "            x_batch, y_batch = (x.to(self.device) for x in next(train_ds))\n",
    "            if alpha is None or epsilon is None:\n",
    "                self._train_batch(x_batch, y_batch)\n",
    "            else:\n",
    "                self._train_batch_dp(x_batch, y_batch, alpha, epsilon / epochs)\n",
    "            \n",
    "            if self.model_steps % train_steps_per_epoch == 0:\n",
    "                train_loss = np.mean(self.batch_losses)\n",
    "                self.train_losses.append(train_loss)\n",
    "                print(f\"Average Train Loss: {train_loss}\")\n",
    "                \n",
    "                self.val_accs.append(model_accuracy(self.model, val_ds, val_size // batch_size, device=DEVICE))\n",
    "                print(f\"Validation Accuracy: {self.val_accs[-1]}\")\n",
    "                end = time.time()\n",
    "                elapsed = end - start\n",
    "                print(f\"Epoch time: {elapsed} seconds\")\n",
    "                print()\n",
    "                self.times.append(elapsed)\n",
    "        \n",
    "        self.test_acc = model_accuracy(self.model, test_ds, test_size // batch_size, device=DEVICE)\n",
    "        print(f\"Final Test Accuracy: {self.test_acc}\")\n",
    "        \n",
    "    def _train_batch(self, x_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Train on the next batch without differential privacy\n",
    "        \"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self.model.forward(x_batch)\n",
    "        loss = self.criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        self.batch_losses.append(loss.item())\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        self.model_steps += 1\n",
    "        \n",
    "    def _train_batch_dp(self, x_batch, y_batch, alpha, epsilon_iter):\n",
    "        \"\"\"\n",
    "        Train on the next batch using differential privacy\n",
    "        \"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Need grad on input for sensitivity; not sure if cloning is needed\n",
    "        x_batch = torch.autograd.Variable(torch.clone(x_batch).to(self.device), requires_grad=True)\n",
    "        \n",
    "        # compute loss\n",
    "        outputs = self.model.forward(x_batch)\n",
    "        loss = self.criterion(outputs, y_batch)\n",
    "        \n",
    "        batch_sensitivities = compute_immediate_sensitivity(\n",
    "            self.model, x_batch, loss\n",
    "        )\n",
    "\n",
    "        batch_sensitivity = torch.max(batch_sensitivities) / len(x_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        # step 4. compute noise\n",
    "        # this is the scale of the Gaussian noise to be added to the batch gradient\n",
    "        sigma = torch.sqrt(\n",
    "            (batch_sensitivity ** 2 * alpha) / (2 * epsilon_iter)\n",
    "        )\n",
    "        \n",
    "        self.batch_losses.append(loss.item())\n",
    "        \n",
    "        # step 5. update gradients with computed sensitivities\n",
    "        with torch.no_grad():\n",
    "            for p in self.model.parameters():\n",
    "                p.grad += sigma * torch.randn(1).to(self.device)\n",
    "        \n",
    "        # perform the a gradient step\n",
    "        self.optimizer.step()\n",
    "        self.model_steps += 1\n",
    "    \n",
    "    def get_sensitivity(self, x_batch, y_batch):\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Need grad on input for sensitivity; not sure if cloning is needed\n",
    "        x_batch = torch.autograd.Variable(torch.clone(x_batch).to(self.device), requires_grad=True)\n",
    "        y_batch = y_batch.to(self.device)\n",
    "        \n",
    "        # compute loss\n",
    "        outputs = self.model.forward(x_batch)\n",
    "        loss = self.criterion(outputs, y_batch)\n",
    "        \n",
    "        batch_sensitivities = compute_immediate_sensitivity(\n",
    "            self.model, x_batch, loss\n",
    "        )\n",
    "\n",
    "        batch_sensitivity = torch.max(batch_sensitivities) / len(x_batch)\n",
    "    \n",
    "    def attack_batch(self, x_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Maximimize local sensitivity w.r.t. the input batch, modifying one sample\n",
    "        \"\"\"\n",
    "        grad_loss = get_grad_loss(x_batch, y_batch)\n",
    "        x_batch_adv = x_batch.copy()\n",
    "        y_batch_adv = y_batch.copy()\n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of Epoch 1\n",
      "Average Train Loss: 1.6474526336669921\n",
      "Validation Accuracy: 0.9501\n",
      "Epoch time: 28.852384090423584 seconds\n",
      "\n",
      "Start of Epoch 2\n",
      "Average Train Loss: 1.5150553749465943\n",
      "Validation Accuracy: 0.9595\n",
      "Epoch time: 28.487991094589233 seconds\n",
      "\n",
      "Start of Epoch 3\n",
      "Average Train Loss: 1.5132265546417236\n",
      "Validation Accuracy: 0.9621\n",
      "Epoch time: 28.448127269744873 seconds\n",
      "\n",
      "Start of Epoch 4\n",
      "Average Train Loss: 1.5028603552627564\n",
      "Validation Accuracy: 0.9654\n",
      "Epoch time: 28.452882766723633 seconds\n",
      "\n",
      "Start of Epoch 5\n",
      "Average Train Loss: 1.49680127910614\n",
      "Validation Accuracy: 0.9702\n",
      "Epoch time: 28.412206411361694 seconds\n",
      "\n",
      "Finished Training\n",
      "Final Test Accuracy: 0.9705\n"
     ]
    }
   ],
   "source": [
    "m = ModelTrainer()\n",
    "m.train(epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of Epoch 1\n",
      "Average Train Loss: 1.726130439453125\n",
      "Validation Accuracy: 0.8644\n",
      "Epoch time: 15.434529066085815 seconds\n",
      "\n",
      "Start of Epoch 2\n",
      "Average Train Loss: 1.586967381477356\n",
      "Validation Accuracy: 0.8879\n",
      "Epoch time: 15.428438186645508 seconds\n",
      "\n",
      "Start of Epoch 3\n",
      "Average Train Loss: 1.5066126013183594\n",
      "Validation Accuracy: 0.9788\n",
      "Epoch time: 15.434360265731812 seconds\n",
      "\n",
      "Start of Epoch 4\n",
      "Average Train Loss: 1.4844073761749268\n",
      "Validation Accuracy: 0.9779\n",
      "Epoch time: 15.40767788887024 seconds\n",
      "\n",
      "Start of Epoch 5\n",
      "Average Train Loss: 1.4818200625228881\n",
      "Validation Accuracy: 0.9775\n",
      "Epoch time: 15.418771982192993 seconds\n",
      "\n",
      "Finished Training\n",
      "Final Test Accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "m2 = ModelTrainer()\n",
    "m2.train(epochs=5, alpha=None, epsilon=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistClassifier(\n",
      "  (conv1): Conv2d(1, 28, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(28, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=12800, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(m.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_ds, train_size = mnist_data_generator(split=\"train\", batch_size=batch_size)\n",
    "x_batch, y_batch = next(train_ds)\n",
    "print(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad_vec(model, criterion, x_batch, y_batch, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Get the gradient vector of the parameters\n",
    "    \"\"\"\n",
    "    model.zero_grad()\n",
    "    #x_grad = torch.autograd.Variable(torch.clone(x_batch).to(device), requires_grad=True)\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "    outputs = model.forward(x_batch)\n",
    "    loss = criterion(outputs, y_batch)\n",
    "    loss.backward()\n",
    "    \n",
    "    grad_vec = torch.cat([param.grad.view(-1) for param in model.parameters()])\n",
    "    return grad_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_point(model, criterion, x_batch, y_batch, x_batch_adv, y_batch_adv, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Return the sensitivity for a specific point (local sensitivity without the maximization over the local region)\n",
    "    \"\"\"\n",
    "    grad_vec = get_grad_vec(model, criterion, x_batch, y_batch, device=device)\n",
    "    grad_vec_adv = get_grad_vec(model, criterion, x_batch_adv, y_batch_adv, device=device)\n",
    "    return torch.norm(grad_vec - grad_vec_adv, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_point2(model, criterion, x_batch_adv, y_batch_adv, grad_vec, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Return the sensitivity for a specific point (local sensitivity without the maximization over the local region)\n",
    "    \"\"\"\n",
    "    grad_vec_adv = get_grad_vec(model, criterion, x_batch_adv, y_batch_adv, device=device)\n",
    "    return torch.norm(grad_vec - grad_vec_adv, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7649e-10, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_point(m.model, m.criterion, x_batch, y_batch, x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5926e-10, device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_point(m.model, m.criterion, x_batch, y_batch, x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_x(model, criterion, x_batch, y_batch, eps_step=0.25, steps=10, device=DEVICE, random_init=True, sign=False):\n",
    "    max_sensitivities = []\n",
    "    x_values = []\n",
    "    grad_vec = get_grad_vec(model, criterion, x_batch, y_batch)\n",
    "    y_batch_adv = torch.clone(y_batch).to(device)\n",
    "    for i in range(len(x_batch)):\n",
    "        print(f\"\\nindex {i}:\")\n",
    "        print(\"----------\")\n",
    "        max_sensitivity = 0\n",
    "        x_value = x_batch[i].cpu().numpy()\n",
    "        x_batch_adv = torch.clone(x_batch).to(device)\n",
    "        if random_init:\n",
    "            x_batch_adv[i] = torch.rand(x_batch[i].shape).to(device)\n",
    "        \n",
    "        sensitivity = sensitivity_point2(model, criterion, x_batch_adv, y_batch_adv, grad_vec).cpu().numpy()\n",
    "        print(f\"step = 0, local sensitivity = {sensitivity}\")\n",
    "        for j in range(steps):\n",
    "            x_grad = compute_local_sensitivity_grad(model, criterion, x_batch_adv, y_batch_adv, grad_vec)\n",
    "            x_grad = x_grad.to(device)\n",
    "            if sign:\n",
    "                x_grad = x_grad.sign()\n",
    "            if x_grad[i].abs().mean() == 0.0:\n",
    "                print(\"    0.0 Gradient. Restarting.\")\n",
    "                x_batch_adv[i] = torch.rand(x_batch[i].shape).to(device)\n",
    "            #else:\n",
    "            #    step = eps_step * x_grad[i] / torch.sqrt(torch.sum(x_grad[i] * x_grad[i]))\n",
    "            #    x_batch_adv[i] = x_batch_adv[i] + step\n",
    "            x_batch_adv[i] = x_batch_adv[i] + eps_step * x_grad[i]\n",
    "            x_batch_adv = x_batch_adv.clamp(0.0, 1.0)\n",
    "            sensitivity = sensitivity_point2(model, criterion, x_batch_adv, y_batch_adv, grad_vec).cpu().numpy()\n",
    "            print(f\"step = {j+1}, local sensitivity = {sensitivity}, grad.abs().mean() = {x_grad[i].abs().mean()}\")\n",
    "            if sensitivity > max_sensitivity:\n",
    "                max_sensitivity = sensitivity\n",
    "                x_value = x_batch_adv[i].cpu().numpy()\n",
    "        max_sensitivities.append(max_sensitivity)\n",
    "        x_values.append(x_value)\n",
    "        print(f\"step = final, local sensitivity = {max_sensitivity}\")\n",
    "    return np.hstack(max_sensitivities), np.stack(x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_train(model, criterion, x_batch, y_batch, device=DEVICE, steps=0):\n",
    "    batch_size = 1\n",
    "    max_sensitivities = []\n",
    "    x_values = []\n",
    "    indexes = []\n",
    "    grad_vec = get_grad_vec(model, criterion, x_batch, y_batch)\n",
    "    y_batch_adv = torch.clone(y_batch).to(device)\n",
    "    for i in range(16): #len(x_batch)):\n",
    "        ds, size = mnist_data_generator(split=\"train\", batch_size=batch_size)\n",
    "        print(f\"\\nindex {i}:\")\n",
    "        print(\"----------\")\n",
    "        max_sensitivity = 0\n",
    "        x_value = x_batch[i].cpu().numpy()\n",
    "        index = -1\n",
    "        x_batch_adv = torch.clone(x_batch).to(device)\n",
    "        sensitivity = sensitivity_point2(model, criterion, x_batch_adv, y_batch_adv, grad_vec).cpu().numpy()   \n",
    "        for j in range(size):\n",
    "            if j == steps:\n",
    "                break\n",
    "            x_j, y_j = next(ds)\n",
    "            x_batch_adv[i] = x_j[0].to(device)\n",
    "            y_batch_adv[i] = y_j[0].to(device)\n",
    "            sensitivity = sensitivity_point2(model, criterion, x_batch_adv, y_batch_adv, grad_vec).cpu().numpy()\n",
    "            #print(f\"step = {j+1}, local sensitivity = {sensitivity}, grad.abs().mean() = {x_grad[i].abs().mean()}\")\n",
    "            if sensitivity > max_sensitivity:\n",
    "                max_sensitivity = sensitivity\n",
    "                x_value = x_batch_adv[i].cpu().numpy()\n",
    "                index = j\n",
    "        max_sensitivities.append(max_sensitivity)\n",
    "        x_values.append(x_value)\n",
    "        indexes.append(index)\n",
    "        print(f\"step = final, local sensitivity = {max_sensitivity}\")\n",
    "    return np.hstack(max_sensitivities), np.stack(x_values), np.array(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "index 0:\n",
      "----------\n",
      "step = final, local sensitivity = 0.2299298644065857\n",
      "\n",
      "index 1:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999446094036102\n",
      "\n",
      "index 2:\n",
      "----------\n",
      "step = final, local sensitivity = 0.2299945056438446\n",
      "\n",
      "index 3:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999455034732819\n",
      "\n",
      "index 4:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999724745750427\n",
      "\n",
      "index 5:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999775409698486\n",
      "\n",
      "index 6:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999775409698486\n",
      "\n",
      "index 7:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999775409698486\n",
      "\n",
      "index 8:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999776899814606\n",
      "\n",
      "index 9:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999775409698486\n",
      "\n",
      "index 10:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999775409698486\n",
      "\n",
      "index 11:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999782860279083\n",
      "\n",
      "index 12:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999785840511322\n",
      "\n",
      "index 13:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999785840511322\n",
      "\n",
      "index 14:\n",
      "----------\n",
      "step = final, local sensitivity = 0.2299967259168625\n",
      "\n",
      "index 15:\n",
      "----------\n",
      "step = final, local sensitivity = 0.22999072074890137\n"
     ]
    }
   ],
   "source": [
    "max_sensitivities, x_values, indexes = attack_train(m.model, m.criterion, x_batch, y_batch, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6628ce06d0>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_values.min(), x_values.max()\n",
    "X = x_values.reshape((16, 28, 28))\n",
    "X = np.hstack(X)\n",
    "Xorig = x_batch.cpu().numpy()\n",
    "Xorig = Xorig.reshape((16, 28, 28))\n",
    "Xorig = np.hstack(Xorig)\n",
    "\n",
    "Xcomb = np.vstack([Xorig, X])\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(Xcomb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "index 0:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.059980735182762146\n",
      "step = 1, local sensitivity = 0.01685219444334507, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.016873888671398163, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 0.01788613386452198, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 0.016873888671398163, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.016873881220817566, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 0.016873888671398163, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.016585232689976692, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.02120441198348999, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 0.018102996051311493, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 10, local sensitivity = 0.04746251180768013, grad.abs().mean() = 0.0\n",
      "step = 11, local sensitivity = 0.016867877915501595, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 0.014466434717178345, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 0.016851069405674934, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.018102996051311493, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 15, local sensitivity = 0.017247330397367477, grad.abs().mean() = 0.0\n",
      "step = 16, local sensitivity = 0.016873888671398163, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.25476542115211487, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.016804425045847893, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 0.03871855512261391, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.018102996051311493, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.25476542115211487\n",
      "\n",
      "index 1:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.003220199840143323\n",
      "step = 1, local sensitivity = 0.03386640176177025, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.0052904998883605, grad.abs().mean() = 0.9987244606018066\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 3, local sensitivity = 0.012866493314504623, grad.abs().mean() = 0.0\n",
      "step = 4, local sensitivity = 1.7736530253387173e-06, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.0052904998883605, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 6, local sensitivity = 0.03156338259577751, grad.abs().mean() = 0.0\n",
      "step = 7, local sensitivity = 0.026267627254128456, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 3.981151621701429e-06, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 0.003050029743462801, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 0.037860143929719925, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 0.13119471073150635, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 0.0052904998883605, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 13, local sensitivity = 0.017644215375185013, grad.abs().mean() = 0.0\n",
      "step = 14, local sensitivity = 0.8459113836288452, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 0.25380417704582214, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.0052904998883605, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 17, local sensitivity = 0.01873704418540001, grad.abs().mean() = 0.0\n",
      "step = 18, local sensitivity = 0.006747623905539513, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 0.0052904998883605, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 20, local sensitivity = 0.027831679210066795, grad.abs().mean() = 0.0\n",
      "step = final, local sensitivity = 0.8459113836288452\n",
      "\n",
      "index 2:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.001082459231838584\n",
      "step = 1, local sensitivity = 2.851857288987958e-06, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 3, local sensitivity = 0.5230419039726257, grad.abs().mean() = 0.0\n",
      "step = 4, local sensitivity = 0.21678663790225983, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 6, local sensitivity = 0.0886581689119339, grad.abs().mean() = 0.0\n",
      "step = 7, local sensitivity = 4.412239377415972e-06, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.21177838742733002, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 10, local sensitivity = 0.07827381044626236, grad.abs().mean() = 0.0\n",
      "step = 11, local sensitivity = 0.12306042015552521, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 0.027904439717531204, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 7.920191933408205e-07, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 15, local sensitivity = 3.7280740798451006e-05, grad.abs().mean() = 0.0\n",
      "step = 16, local sensitivity = 1.687945314188255e-06, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 18, local sensitivity = 0.020803719758987427, grad.abs().mean() = 0.0\n",
      "step = 19, local sensitivity = 4.960841124557192e-07, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.5230419039726257\n",
      "\n",
      "index 3:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.013171685859560966\n",
      "step = 1, local sensitivity = 2.6861982860282296e-06, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.016607781872153282, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 0.20660927891731262, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 5, local sensitivity = 0.004438234958797693, grad.abs().mean() = 0.0\n",
      "step = 6, local sensitivity = 2.8813810786232352e-06, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 8, local sensitivity = 0.002900950610637665, grad.abs().mean() = 0.0\n",
      "step = 9, local sensitivity = 0.06178180128335953, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 11, local sensitivity = 0.008342618122696877, grad.abs().mean() = 0.0\n",
      "step = 12, local sensitivity = 0.02300466038286686, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 9.160496119875461e-05, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 15, local sensitivity = 0.00038579755346290767, grad.abs().mean() = 0.0\n",
      "step = 16, local sensitivity = 0.010166686028242111, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 18, local sensitivity = 0.0368088036775589, grad.abs().mean() = 0.0\n",
      "step = 19, local sensitivity = 2.757399897745927e-06, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.20660927891731262\n",
      "\n",
      "index 4:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.07217318564653397\n",
      "step = 1, local sensitivity = 0.02630138397216797, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.0014089661417528987, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 3, local sensitivity = 0.02180270291864872, grad.abs().mean() = 0.0\n",
      "step = 4, local sensitivity = 8.94020740815904e-06, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 8.991664799395949e-06, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 0.05354947969317436, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.0002929814800154418, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.0014089661417528987, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 9, local sensitivity = 0.00010747359920060262, grad.abs().mean() = 0.0\n",
      "step = 10, local sensitivity = 0.09453032165765762, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 0.0014089661417528987, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 12, local sensitivity = 0.15267495810985565, grad.abs().mean() = 0.0\n",
      "step = 13, local sensitivity = 0.017069265246391296, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.0014089661417528987, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 15, local sensitivity = 0.04185733199119568, grad.abs().mean() = 0.0\n",
      "step = 16, local sensitivity = 0.005614080931991339, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.0903320387005806, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.0014089661417528987, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 19, local sensitivity = 0.01890682987868786, grad.abs().mean() = 0.0\n",
      "step = 20, local sensitivity = 0.010601897723972797, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.15267495810985565\n",
      "\n",
      "index 5:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.04490014910697937\n",
      "step = 1, local sensitivity = 0.0006567845703102648, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.007307448424398899, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 3, local sensitivity = 1.204857587814331, grad.abs().mean() = 0.0\n",
      "step = 4, local sensitivity = 1.3761009540758096e-06, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.007307448424398899, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 6, local sensitivity = 0.05182519182562828, grad.abs().mean() = 0.0\n",
      "step = 7, local sensitivity = 0.004685236606746912, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.007307448424398899, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 9, local sensitivity = 0.0014716702280566096, grad.abs().mean() = 0.0\n",
      "step = 10, local sensitivity = 2.851130011549685e-05, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 0.007307448424398899, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 12, local sensitivity = 0.003456542734056711, grad.abs().mean() = 0.0\n",
      "step = 13, local sensitivity = 1.5741214156150818e-05, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.007307448424398899, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 15, local sensitivity = 0.02392783761024475, grad.abs().mean() = 0.0\n",
      "step = 16, local sensitivity = 2.1021845896029845e-05, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.007307448424398899, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 18, local sensitivity = 0.0005126847536303103, grad.abs().mean() = 0.0\n",
      "step = 19, local sensitivity = 4.322604581830092e-06, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.007307448424398899, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 1.204857587814331\n",
      "\n",
      "index 6:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.08354832231998444\n",
      "step = 1, local sensitivity = 2.807242367453e-07, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 3, local sensitivity = 0.01302451640367508, grad.abs().mean() = 0.0\n",
      "step = 4, local sensitivity = 6.747213898705695e-09, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.0993594154715538, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 0.031993962824344635, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.002880464307963848, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.09417127817869186, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 10, local sensitivity = 0.0008609910146333277, grad.abs().mean() = 0.0\n",
      "step = 11, local sensitivity = 1.014462736037558e-09, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 0.14515931904315948, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 14, local sensitivity = 0.073956198990345, grad.abs().mean() = 0.0\n",
      "step = 15, local sensitivity = 0.01341844443231821, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.03382456302642822, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 18, local sensitivity = 0.002560738706961274, grad.abs().mean() = 0.0\n",
      "step = 19, local sensitivity = 0.09074254333972931, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 1.1755637352450776e-08, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.14515931904315948\n",
      "\n",
      "index 7:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.0037862195167690516\n",
      "step = 1, local sensitivity = 1.0774015188217163, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.00016012645210139453, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 0.001542773679830134, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 5, local sensitivity = 0.08980543166399002, grad.abs().mean() = 0.0\n",
      "step = 6, local sensitivity = 0.006200733128935099, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 8, local sensitivity = 0.01642315648496151, grad.abs().mean() = 0.0\n",
      "step = 9, local sensitivity = 2.478224132573814e-06, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 11, local sensitivity = 0.0027448777109384537, grad.abs().mean() = 0.0\n",
      "step = 12, local sensitivity = 2.6333892844121465e-09, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 7.242188644340786e-07, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 15, local sensitivity = 0.012125973589718342, grad.abs().mean() = 0.0\n",
      "step = 16, local sensitivity = 0.004108781460672617, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 18, local sensitivity = 0.05005557835102081, grad.abs().mean() = 0.0\n",
      "step = 19, local sensitivity = 0.05303046852350235, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.048863478004932404, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 1.0774015188217163\n",
      "\n",
      "index 8:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.007533100433647633\n",
      "step = 1, local sensitivity = 0.014239496551454067, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 3, local sensitivity = 0.005370759405195713, grad.abs().mean() = 0.0\n",
      "step = 4, local sensitivity = 0.09536442905664444, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 6, local sensitivity = 0.0003748939489014447, grad.abs().mean() = 0.0\n",
      "step = 7, local sensitivity = 0.09371794015169144, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 9, local sensitivity = 0.04698978364467621, grad.abs().mean() = 0.0\n",
      "step = 10, local sensitivity = 0.14010189473628998, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 12, local sensitivity = 0.022968420758843422, grad.abs().mean() = 0.0\n",
      "step = 13, local sensitivity = 0.042423177510499954, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 15, local sensitivity = 0.09507746994495392, grad.abs().mean() = 0.0\n",
      "step = 16, local sensitivity = 6.35177711956203e-05, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.0014089366886764765, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 18, local sensitivity = 0.17708683013916016, grad.abs().mean() = 0.0\n",
      "step = 19, local sensitivity = 0.2486027628183365, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 1.0174396265938412e-05, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.2486027628183365\n",
      "\n",
      "index 9:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.0271476898342371\n",
      "step = 1, local sensitivity = 0.0031163045205175877, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 1.0509513685974525e-06, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 0.19067564606666565, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 6.685731932520866e-05, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.0022652859333902597, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 7, local sensitivity = 0.2837751805782318, grad.abs().mean() = 0.0\n",
      "step = 8, local sensitivity = 0.18341690301895142, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 0.003861170494928956, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 2.9323479755483106e-10, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 1.0221624506812077e-05, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 13, local sensitivity = 0.05263528972864151, grad.abs().mean() = 0.0\n",
      "step = 14, local sensitivity = 0.11377608776092529, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 0.0006132945418357849, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.00030821788823232055, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 3.0436553970503155e-06, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 19, local sensitivity = 0.08796476572751999, grad.abs().mean() = 0.0\n",
      "step = 20, local sensitivity = 1.2169640064239502, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 1.2169640064239502\n",
      "\n",
      "index 10:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.038066137582063675\n",
      "step = 1, local sensitivity = 0.004599604289978743, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.08977165818214417, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 0.7154256701469421, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 0.00023180959396995604, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 2.6075228087840685e-10, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 2.774809271244294e-10, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 4.557131887850119e-06, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.20800849795341492, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 2.8862076617564014e-10, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 5.123372837090301e-10, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 2.943882645922713e-05, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 13, local sensitivity = 0.0006634874152950943, grad.abs().mean() = 0.0\n",
      "step = 14, local sensitivity = 1.6685817241668701, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 2.1851465703548456e-07, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.004988701082766056, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.011275452561676502, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 19, local sensitivity = 0.11239539831876755, grad.abs().mean() = 0.0\n",
      "step = 20, local sensitivity = 2.409742849707186e-09, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 1.6685817241668701\n",
      "\n",
      "index 11:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.0330965518951416\n",
      "step = 1, local sensitivity = 0.032398857176303864, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.006677675060927868, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 3, local sensitivity = 0.01859668828547001, grad.abs().mean() = 0.0\n",
      "step = 4, local sensitivity = 5.273873284750152e-07, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.0018380064284428954, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 3.8647063774988055e-05, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.10174520313739777, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.006677675060927868, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 9, local sensitivity = 0.019358374178409576, grad.abs().mean() = 0.0\n",
      "step = 10, local sensitivity = 0.007343376986682415, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 5.43449459655676e-07, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 0.04828570783138275, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 0.006677675060927868, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 14, local sensitivity = 0.0008416195632889867, grad.abs().mean() = 0.0\n",
      "step = 15, local sensitivity = 0.0010219807736575603, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.006677675060927868, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 17, local sensitivity = 0.10905030369758606, grad.abs().mean() = 0.0\n",
      "step = 18, local sensitivity = 5.266056746222603e-07, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 0.11634109914302826, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.006677675060927868, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.11634109914302826\n",
      "\n",
      "index 12:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.0012097127037122846\n",
      "step = 1, local sensitivity = 0.04395507276058197, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 3, local sensitivity = 0.005446386989206076, grad.abs().mean() = 0.0\n",
      "step = 4, local sensitivity = 1.3580147424363531e-06, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 6, local sensitivity = 0.08316195011138916, grad.abs().mean() = 0.0\n",
      "step = 7, local sensitivity = 1.549703920744605e-09, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.25155502557754517, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 10, local sensitivity = 0.017623167484998703, grad.abs().mean() = 0.0\n",
      "step = 11, local sensitivity = 1.0528659544206675e-07, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 7.903068035375327e-05, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 0.06576083600521088, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 7.093262684065849e-05, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 1.0116956218553241e-05, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.9990992546081543, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.0014089375035837293, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 18, local sensitivity = 0.002090004738420248, grad.abs().mean() = 0.0\n",
      "step = 19, local sensitivity = 0.2718198299407959, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.11752700805664062, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.9990992546081543\n",
      "\n",
      "index 13:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.021638408303260803\n",
      "step = 1, local sensitivity = 0.08072612434625626, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.005977746099233627, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 3, local sensitivity = 0.011606013402342796, grad.abs().mean() = 0.0\n",
      "step = 4, local sensitivity = 6.817863322794437e-05, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.005977746099233627, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 6, local sensitivity = 0.000649508903734386, grad.abs().mean() = 0.0\n",
      "step = 7, local sensitivity = 8.278084351331927e-06, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.005977746099233627, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 9, local sensitivity = 0.0064067840576171875, grad.abs().mean() = 0.0\n",
      "step = 10, local sensitivity = 5.114083023727289e-07, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 0.005977746099233627, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 12, local sensitivity = 0.0004610166943166405, grad.abs().mean() = 0.0\n",
      "step = 13, local sensitivity = 0.004875681828707457, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.05559857562184334, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 0.00010456968448124826, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.005977746099233627, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 17, local sensitivity = 0.00048795860493555665, grad.abs().mean() = 0.0\n",
      "step = 18, local sensitivity = 0.06592143326997757, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 6.105336069595069e-05, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.005977746099233627, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.08072612434625626\n",
      "\n",
      "index 14:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.00014652902609668672\n",
      "step = 1, local sensitivity = 0.04095234349370003, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.0014090886106714606, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 3, local sensitivity = 0.05393616482615471, grad.abs().mean() = 0.0\n",
      "step = 4, local sensitivity = 0.02613135613501072, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.007076252717524767, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 0.0014090886106714606, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 7, local sensitivity = 0.002537582768127322, grad.abs().mean() = 0.0\n",
      "step = 8, local sensitivity = 0.020617693662643433, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 0.0014090886106714606, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 10, local sensitivity = 0.03727054223418236, grad.abs().mean() = 0.0\n",
      "step = 11, local sensitivity = 0.0016719551058486104, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 0.0014090886106714606, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 13, local sensitivity = 0.006717093288898468, grad.abs().mean() = 0.0\n",
      "step = 14, local sensitivity = 0.032248690724372864, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 0.0014090886106714606, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 16, local sensitivity = 0.00019873672863468528, grad.abs().mean() = 0.0\n",
      "step = 17, local sensitivity = 4.1701965528773144e-05, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.0014090886106714606, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 19, local sensitivity = 0.010010449215769768, grad.abs().mean() = 0.0\n",
      "step = 20, local sensitivity = 2.071578273898922e-05, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.05393616482615471\n",
      "\n",
      "index 15:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.04916157200932503\n",
      "step = 1, local sensitivity = 9.3192356871441e-06, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.012838427908718586, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 1.284339577978244e-05, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 0.04140651226043701, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.006782739423215389, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 6, local sensitivity = 0.020170172676444054, grad.abs().mean() = 0.0\n",
      "step = 7, local sensitivity = 0.07245459407567978, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.006782739423215389, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 9, local sensitivity = 0.014431913383305073, grad.abs().mean() = 0.0\n",
      "step = 10, local sensitivity = 0.002549130003899336, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 0.006782739423215389, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 12, local sensitivity = 0.014131560921669006, grad.abs().mean() = 0.0\n",
      "step = 13, local sensitivity = 0.05523267015814781, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.006782739423215389, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 15, local sensitivity = 0.00911693088710308, grad.abs().mean() = 0.0\n",
      "step = 16, local sensitivity = 0.006207366939634085, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.006782739423215389, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 18, local sensitivity = 0.10057678073644638, grad.abs().mean() = 0.0\n",
      "step = 19, local sensitivity = 0.014836501330137253, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.1624734252691269, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.1624734252691269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6628f629d0>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_sensitivities, x_values = attack_x(m.model, m.criterion, x_batch, y_batch, steps=20, eps_step=50, random_init=True, sign=True)\n",
    "import matplotlib.pyplot as plt\n",
    "x_values.min(), x_values.max()\n",
    "X = x_values.reshape((16, 28, 28))\n",
    "X = np.hstack(X)\n",
    "Xorig = x_batch.cpu().numpy()\n",
    "Xorig = Xorig.reshape((16, 28, 28))\n",
    "Xorig = np.hstack(Xorig)\n",
    "\n",
    "Xcomb = np.vstack([Xorig, X])\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(Xcomb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "index 0:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.004952771123498678\n",
      "step = 1, local sensitivity = 0.13387128710746765, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 3.9505471810530324e-11, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 2.353284754563756e-11, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 4, local sensitivity = 0.05211900547146797, grad.abs().mean() = 0.0\n",
      "step = 5, local sensitivity = 0.06549323350191116, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 2.5978285494998588e-11, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 7.944114489226006e-15, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.012541144154965878, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 1.2658615560212638e-06, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 6.19036472926382e-06, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 2.847716637152664e-14, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 2.3533900522787476e-11, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 0.2221350222826004, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 3.154955116602132e-11, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 3.1549547696574365e-11, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.028734365478157997, grad.abs().mean() = 0.9757652878761292\n",
      "step = 17, local sensitivity = 2.3532797238656755e-11, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.0008892528130672872, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 5.0118726946379866e-09, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.0057502924464643, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.2221350222826004\n",
      "\n",
      "index 1:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.6498450636863708\n",
      "step = 1, local sensitivity = 3.154873931543456e-11, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 2, local sensitivity = 0.056193187832832336, grad.abs().mean() = 0.0\n",
      "step = 3, local sensitivity = 1.6316391793225193e-07, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 1.50597312398304e-08, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 2.318683786639575e-11, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 3.154955116602132e-11, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.004940326791256666, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.014377190731465816, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 4.588456350984593e-12, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 1.436777434494444e-14, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 1.6041431827621896e-14, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 12, local sensitivity = 1.3617854118347168, grad.abs().mean() = 0.0\n",
      "step = 13, local sensitivity = 5.188685463508591e-06, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 1.605955833269314e-14, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 0.02865554951131344, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.021248463541269302, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 1.607960082629107e-14, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 3.161752110125704e-11, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 0.01678629405796528, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 1.7321633710709605e-11, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 1.3617854118347168\n",
      "\n",
      "index 2:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.023858780041337013\n",
      "step = 1, local sensitivity = 3.475139465081156e-07, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 2.313315511370817e-11, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 1.5610987979738922e-13, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 1.1421174065089773e-13, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.0007632420165464282, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 0.0008263350464403629, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.0018618135945871472, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 1.561097307195905e-13, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 0.0002616501005832106, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 2.1609346256834527e-11, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 3.1626035124077134e-11, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 0.08842982351779938, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 2.6563532189854966e-12, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.016218021512031555, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 0.28874894976615906, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 3.345197896464924e-08, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 2.6122140908690916e-11, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 18, local sensitivity = 0.28063344955444336, grad.abs().mean() = 0.0\n",
      "step = 19, local sensitivity = 2.3133429200017375e-11, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 2.3546003688479367e-11, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.28874894976615906\n",
      "\n",
      "index 3:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.004590198863297701\n",
      "step = 1, local sensitivity = 0.11818532645702362, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 4.4734235416399315e-05, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 2.3092019615922332e-11, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 5.136913046044356e-07, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 2.5469522324517158e-11, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 3.391921609363635e-06, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 1.7803824386986022e-11, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 2.29955054997788e-09, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 1.3049367359255215e-12, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 4.245257150614634e-05, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 0.2276245355606079, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 2.315824962351165e-11, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 1.3049367359255215e-12, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 2.6453310028595745e-11, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 3.80518122256035e-06, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 1.397289185398054e-12, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 2.7260122978378654e-11, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 6.686920528409246e-07, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 4.999519465087587e-09, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 1.64149679959813e-10, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.2276245355606079\n",
      "\n",
      "index 4:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.03540857136249542\n",
      "step = 1, local sensitivity = 0.01823456399142742, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 1.0382172149547841e-05, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 2.3532797238656755e-11, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 3.154955463546827e-11, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 3.1549547696574365e-11, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 0.02477370761334896, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 1.4345379051317053e-10, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 1.7806103813633456e-10, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 2.3132627757771473e-11, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 1.7055616901434645e-12, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 2.3121744102683195e-11, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 7.944122112522531e-15, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 1.776358533466145e-15, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 2.451527479283011e-12, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 3.1549547696574365e-11, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 3.1549547696574365e-11, grad.abs().mean() = 0.9987244606018066\n",
      "step = 17, local sensitivity = 0.00152416224591434, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.007766932714730501, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 0.00012790015898644924, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 9.23792021611386e-14, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.02477370761334896\n",
      "\n",
      "index 5:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.04801556095480919\n",
      "step = 1, local sensitivity = 8.236185067289625e-09, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.0005791500443592668, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 0.22936886548995972, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 2.8691746895015413e-11, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.394399493932724, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 3.0735650136115567e-11, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 3.161751763181009e-11, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 1.0168537019350499e-12, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 3.1549547696574365e-11, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 10, local sensitivity = 0.013582942076027393, grad.abs().mean() = 0.0\n",
      "step = 11, local sensitivity = 1.7277211883381938e-09, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 1.5979473603697225e-12, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 1.4875213283360722e-09, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 2.3132908782974582e-11, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 15, local sensitivity = 0.08755455166101456, grad.abs().mean() = 0.0\n",
      "step = 16, local sensitivity = 7.1091144920204e-15, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 1.3907587081973816e-08, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 4.484154032979859e-06, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 2.3132908782974582e-11, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.001961029600352049, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.394399493932724\n",
      "\n",
      "index 6:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.06905995309352875\n",
      "step = 1, local sensitivity = 0.004240305628627539, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 2, local sensitivity = 0.08959419280290604, grad.abs().mean() = 0.0\n",
      "step = 3, local sensitivity = 0.004240305628627539, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 0.004240305628627539, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.004245213698595762, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 0.004240305628627539, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.03099312074482441, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.004240305628627539, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 0.005464698188006878, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 0.004240305628627539, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 0.03347774222493172, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 0.004240305628627539, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 0.26895397901535034, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.005223511252552271, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 0.004240305628627539, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.004240608308464289, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.004240305628627539, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.004240305628627539, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 0.004893521312624216, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 0.151084765791893, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.26895397901535034\n",
      "\n",
      "index 7:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.055303771048784256\n",
      "step = 1, local sensitivity = 0.21832622587680817, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 3.8326670619426295e-05, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 3.7746874568256317e-06, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 2.263739770569373e-05, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 2.3132908782974582e-11, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 0.15651996433734894, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.0009180433116853237, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 1.776363192147355e-15, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 1.572290919682473e-08, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 2.6123276718886812e-12, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 3.942407147405902e-06, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 2.3217254941504395e-12, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 1.71602896443801e-05, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.0002775969624053687, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 7.324107547659539e-15, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.0006055235280655324, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 7.82785303243827e-09, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.00874165166169405, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 1.8225397319798775e-12, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 2.1514049421966774e-06, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.21832622587680817\n",
      "\n",
      "index 8:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.0020971642807126045\n",
      "step = 1, local sensitivity = 4.3524378270376474e-05, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.11758826673030853, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 0.0003870705550070852, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 0.14171795547008514, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 3.1548728907093704e-11, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 8.082683677912428e-08, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 9.685823254557135e-10, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 2.357016491705277e-11, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 2.3727513009941248e-11, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 1.3265178040455794e-06, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 0.2669464945793152, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 2.313262949249495e-11, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 0.2215328961610794, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.2552732825279236, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 4.623228549957275, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 3.958466887610257e-10, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.4219553768634796, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 1.4449179699949077e-11, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 0.001003962242975831, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 3.161751763181009e-11, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 4.623228549957275\n",
      "\n",
      "index 9:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.8441781997680664\n",
      "step = 1, local sensitivity = 2.6945997516625297e-12, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.210308238863945, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 0.23100347816944122, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 2.0927544142068655e-09, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.19402028620243073, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 0.012486410327255726, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 2.3571538818045745e-11, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 3.161751763181009e-11, grad.abs().mean() = 0.9987244606018066\n",
      "step = 9, local sensitivity = 2.566142396552434e-17, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 2.0302736922217512e-11, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 5.657606674813742e-11, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 2.357154055276922e-11, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 7.373683388323116e-07, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 2.3143820193638476e-11, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 3.2422571571988357e-11, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 2.930168518304292e-14, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 3.1549547696574365e-11, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 7.344485466304583e-15, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 2.4852295609889552e-05, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 7.105427357601002e-15, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.23100347816944122\n",
      "\n",
      "index 10:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.01151496171951294\n",
      "step = 1, local sensitivity = 0.16590574383735657, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 8.859603606303779e-10, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 0.004455447196960449, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 6.16388433627435e-08, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 8.859603606303779e-10, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 6, local sensitivity = 0.005775224417448044, grad.abs().mean() = 0.0\n",
      "step = 7, local sensitivity = 0.006872350350022316, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 8.853126010066603e-10, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 0.4019872844219208, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 8.32685202567518e-07, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 8.859603606303779e-10, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 3.2434050467600173e-07, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 8.859602496080754e-10, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 0.018049435690045357, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 8.859603606303779e-10, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 0.027686581015586853, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.006230611354112625, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.0005519298720173538, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 1.0075515977092664e-09, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 8.853126010066603e-10, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.4019872844219208\n",
      "\n",
      "index 11:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.04675707966089249\n",
      "step = 1, local sensitivity = 4.4709715096846736e-11, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 2.7438687433267717e-10, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 2.907635243687423e-11, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 4, local sensitivity = 0.00214087450876832, grad.abs().mean() = 0.0\n",
      "step = 5, local sensitivity = 0.0042832642793655396, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 0.043333616107702255, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.006065952125936747, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 2.3132910517698058e-11, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 3.1549547696574365e-11, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 2.3132908782974582e-11, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 11, local sensitivity = 0.035346243530511856, grad.abs().mean() = 0.0\n",
      "step = 12, local sensitivity = 1.8449116012675404e-08, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 3.6113488501715585e-12, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 2.3132908782974582e-11, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 15, local sensitivity = 0.11292532086372375, grad.abs().mean() = 0.0\n",
      "step = 16, local sensitivity = 0.003434061538428068, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 2.4170454526739604e-09, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.06319406628608704, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 9.095225657687611e-13, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 3.972057244613003e-15, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.11292532086372375\n",
      "\n",
      "index 12:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.3838615417480469\n",
      "step = 1, local sensitivity = 7.94425170856346e-15, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 0.21301598846912384, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 2.477171801018585e-09, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 1.1762659823943977e-06, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 0.00014051931793801486, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 2.3443538776923845e-10, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 3.5181381115309356e-18, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 0.1898321956396103, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 3.501970786601305e-05, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 0.004035893827676773, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 0.050157368183135986, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 2.6934498468383916e-13, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 6.379436712222741e-08, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 7.105428204633949e-15, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 8.143001213373104e-15, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 6.797515883505412e-09, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 2.3663446757637985e-09, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 2.3536445362126734e-11, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 2.3132908782974582e-11, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 5.930224870098755e-05, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.21301598846912384\n",
      "\n",
      "index 13:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.01342523843050003\n",
      "step = 1, local sensitivity = 0.11223064363002777, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 2.970316792527683e-08, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 0.001411458826623857, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 2.9700300885338038e-08, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 2.9700391479536847e-08, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 4.001283571142267e-08, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.10489779710769653, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 3.027062689398008e-08, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 0.009281597100198269, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 2.9708870030731305e-08, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 2.9700141013222492e-08, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 1.6317187601089245e-06, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 2.970447354755379e-08, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 2.9700215620209747e-08, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 15, local sensitivity = 0.07117727398872375, grad.abs().mean() = 0.0\n",
      "step = 16, local sensitivity = 2.9700141013222492e-08, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 17, local sensitivity = 0.004185603931546211, grad.abs().mean() = 0.0\n",
      "step = 18, local sensitivity = 1.6666945157339796e-05, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 0.0027037926483899355, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 2.8275362637941726e-06, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.11223064363002777\n",
      "\n",
      "index 14:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.003403029404580593\n",
      "step = 1, local sensitivity = 3.608449716807627e-08, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 1.720417384942774e-11, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 3.1549547696574365e-11, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 3.1528937816619873, grad.abs().mean() = 1.0\n",
      "step = 5, local sensitivity = 3.169475099040753e-11, grad.abs().mean() = 1.0\n",
      "step = 6, local sensitivity = 9.133515050052665e-06, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 0.2941861152648926, grad.abs().mean() = 1.0\n",
      "step = 8, local sensitivity = 3.161751763181009e-11, grad.abs().mean() = 1.0\n",
      "step = 9, local sensitivity = 2.6072936058044434, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 3.1549547696574365e-11, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 3.161751763181009e-11, grad.abs().mean() = 0.04209183529019356\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 12, local sensitivity = 0.02301505021750927, grad.abs().mean() = 0.0\n",
      "step = 13, local sensitivity = 2.693690776824951, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 2.3744870653041872e-11, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 7.99620439306814e-12, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 7.129374673085775e-15, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 0.3007448613643646, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 5.476335445564473e-06, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 0.0006729725864715874, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 2.9824122338428793e-11, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 3.1528937816619873\n",
      "\n",
      "index 15:\n",
      "----------\n",
      "step = 0, local sensitivity = 0.6119759678840637\n",
      "step = 1, local sensitivity = 2.7903169358411972e-11, grad.abs().mean() = 1.0\n",
      "step = 2, local sensitivity = 2.31326763300288e-11, grad.abs().mean() = 1.0\n",
      "step = 3, local sensitivity = 2.3132627757771473e-11, grad.abs().mean() = 1.0\n",
      "step = 4, local sensitivity = 2.3532797238656755e-11, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 5, local sensitivity = 0.18934877216815948, grad.abs().mean() = 0.0\n",
      "step = 6, local sensitivity = 2.6179744483378897e-10, grad.abs().mean() = 1.0\n",
      "step = 7, local sensitivity = 2.3122028597333255e-11, grad.abs().mean() = 1.0\n",
      "    0.0 Gradient. Restarting.\n",
      "step = 8, local sensitivity = 0.013072788715362549, grad.abs().mean() = 0.0\n",
      "step = 9, local sensitivity = 0.07148764282464981, grad.abs().mean() = 1.0\n",
      "step = 10, local sensitivity = 0.02798760123550892, grad.abs().mean() = 1.0\n",
      "step = 11, local sensitivity = 2.6542034629178923e-12, grad.abs().mean() = 1.0\n",
      "step = 12, local sensitivity = 7.789624760334846e-06, grad.abs().mean() = 1.0\n",
      "step = 13, local sensitivity = 5.94673746009966e-12, grad.abs().mean() = 1.0\n",
      "step = 14, local sensitivity = 3.425868963513601e-11, grad.abs().mean() = 1.0\n",
      "step = 15, local sensitivity = 3.67259306299772e-10, grad.abs().mean() = 1.0\n",
      "step = 16, local sensitivity = 1.6705524116811254e-11, grad.abs().mean() = 1.0\n",
      "step = 17, local sensitivity = 4.8864512436352925e-09, grad.abs().mean() = 1.0\n",
      "step = 18, local sensitivity = 0.4705672860145569, grad.abs().mean() = 1.0\n",
      "step = 19, local sensitivity = 6.617893733018576e-11, grad.abs().mean() = 1.0\n",
      "step = 20, local sensitivity = 7.324110935791328e-15, grad.abs().mean() = 1.0\n",
      "step = final, local sensitivity = 0.4705672860145569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f66292a95d0>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_sensitivities, x_values = attack_x(m2.model, m2.criterion, x_batch, y_batch, steps=20, eps_step=0.5, random_init=True, sign=True)\n",
    "x_values.min(), x_values.max()\n",
    "X = x_values.reshape((16, 28, 28))\n",
    "X = np.hstack(X)\n",
    "Xorig = x_batch.cpu().numpy()\n",
    "Xorig = Xorig.reshape((16, 28, 28))\n",
    "Xorig = np.hstack(Xorig)\n",
    "\n",
    "Xcomb = np.vstack([Xorig, X])\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(Xcomb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735.0"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.9375) * 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_y(model, criterion, x_batch, y_batch, n=10, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Determine the worst case sensitivity by switching the value of y\n",
    "    \"\"\"\n",
    "    max_sensitivities = []\n",
    "    y_values = []\n",
    "    grad_vec = get_grad_vec(model, criterion, x_batch, y_batch, device=device)\n",
    "    for i in range(len(x_batch)):\n",
    "        max_sensitivity = 0\n",
    "        y_value = y_batch[i].cpu().numpy()\n",
    "        for j in range(1, n):\n",
    "            y_batch_adv = torch.clone(y_batch)\n",
    "            y_batch_adv[i] = (y_batch[i] + j) % n\n",
    "            grad_vec_adv = get_grad_vec(model, criterion, x_batch, y_batch_adv, device=DEVICE)\n",
    "            sensitivity = torch.norm(grad_vec - grad_vec_adv, p=2).cpu().numpy()\n",
    "            if sensitivity > max_sensitivity:\n",
    "                max_sensitivity = sensitivity\n",
    "                y_value = y_batch_adv[i].cpu().numpy()\n",
    "        max_sensitivities.append(max_sensitivity)\n",
    "        y_values.append(y_value)\n",
    "    return np.hstack(max_sensitivities), np.hstack(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sensitivities, y_values = attack_y(m.model, m.criterion, x_batch, y_batch, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.8087397e-09, 4.5583787e-05, 1.7107064e-06, 1.8623197e-08,\n",
       "       5.6080234e-09, 5.7029808e-09, 1.1994807e-03, 1.3006899e-05,\n",
       "       5.3975262e-02, 5.8730079e-09, 4.9425522e-05, 5.2547442e-09,\n",
       "       7.3737468e-08, 5.2461380e-01, 9.0845473e-09, 6.9930316e-08],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2,  2, -3,  8, -5,  4,  5, -1,  5,  3,  3, -2,  3, -3,  7,  2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values - y_batch.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "immediate_sensitivities = compute_immediate_sensitivity_full(m.model, m.criterion, x_batch, y_batch).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.039514653 0.49594343 0.07967573\n",
      "2.945177e-10 2.7165287e-13 1084.1692\n",
      "6.915192e-07 2.438257e-07 2.836121\n",
      "5.7981288e-06 2.3888936e-06 2.427119\n",
      "2.1054919e-05 5.6466006e-06 3.728778\n",
      "2.9764743e-10 5.353799e-16 555955.56\n",
      "3.0935168e-10 7.526046e-12 41.104145\n",
      "3.1393993e-10 3.074149e-11 10.2122555\n",
      "7.869117e-07 3.1886884e-07 2.4678226\n",
      "2.8855662e-10 2.0095353e-12 143.5937\n",
      "3.0389588e-10 2.1031386e-10 1.4449636\n",
      "1.1512084e-06 6.829997e-06 0.16855182\n",
      "2.9793532e-10 7.3394934e-16 405934.44\n",
      "2.8294303e-10 4.354814e-13 649.72473\n",
      "4.7116228e-05 6.768869e-07 69.60724\n",
      "2.2214237e-05 3.912854e-06 5.6772466\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(max_sensitivities, immediate_sensitivities):\n",
    "    local_smoothness_lower_bound = i / j\n",
    "    print(i, j, local_smoothness_lower_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146])\n"
     ]
    }
   ],
   "source": [
    "print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david.slater/.conda/envs/csl/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "v.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.cat([param.view(-1) for param in m.model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.12015969, dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(w, p=2).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-3c0f62251c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msensitivity_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-85-85a14f5d8f52>\u001b[0m in \u001b[0;36msensitivity_point\u001b[0;34m(model, criterion, x_batch, y_batch, x_batch_adv, y_batch_adv, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msensitivity\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mspecific\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0msensitivity\u001b[0m \u001b[0mwithout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmaximization\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlocal\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgrad_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_grad_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mgrad_vec_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_grad_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_vec\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrad_vec_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-8b53eefe6246>\u001b[0m in \u001b[0;36mget_grad_vec\u001b[0;34m(model, criterion, x_batch, y_batch, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mGet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#x_grad = torch.autograd.Variable(torch.clone(x_batch).to(device), requires_grad=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/csl/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "sensitivity_point(m.model, m.criterion, x_batch, y_batch, x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_batch + 1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 1, 5, 2, 0, 3, 2, 4, 2, 5, 4, 6, 4, 7, 2, 8])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_batch+1) % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch_2 = (y_batch+1) % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_sensitivity(x_batch, y_batch.to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_sensitivity_grad_vec(model, criterion, x_batch, y_batch, grad_vec, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Get the gradient of the objective of the maximization w.r.t. the input x_batch\n",
    "    \n",
    "    || D_W(x) - grad_vec ||2\n",
    "    \"\"\"\n",
    "    model.zero_grad()\n",
    "    #x_grad = torch.autograd.Variable(torch.clone(x_batch).to(device), requires_grad=True)\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "    outputs = model.forward(x_grad)\n",
    "    loss = criterion(outputs, y_batch)\n",
    "    loss.backward()\n",
    "    \n",
    "    grad_vec = torch.cat([param.grad.view(-1) for param in model.parameters()])\n",
    "    return grad_vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
