{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "po_2rTwrOiEf",
    "outputId": "e38f056c-a0a8-438f-b65c-df5ad9b214ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from IPython import display\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(7)\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True, context=\"talk\")\n",
    "\n",
    "%matplotlib inline\n",
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility for loading up the dataset\n",
    "\n",
    "def load_adult_data(path):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "                    'martial_status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                    'capital_gain', 'capital_loss', 'hours_per_week', 'country', 'target']\n",
    "    input_data = (pd.read_csv(path, names=column_names,\n",
    "                              na_values=\"?\", sep=r'\\s*,\\s*', engine='python')\n",
    "                  .loc[lambda df: df['race'].isin(['White', 'Black'])])\n",
    "\n",
    "    # targets; 1 when someone makes over 50k , otherwise 0\n",
    "    y = (input_data['target'] == '>50K').astype(int)\n",
    "\n",
    "    # features; note that the 'target' and sentive attribute columns are dropped\n",
    "    X = (input_data\n",
    "         .drop(columns=['target', 'fnlwgt'])\n",
    "         .fillna('Unknown')\n",
    "         .pipe(pd.get_dummies, drop_first=True))\n",
    "\n",
    "    y = y.to_frame()\n",
    "    for col in X.columns:\n",
    "      X[col] = X[col].astype('float32')\n",
    "\n",
    "    for col in y.columns:\n",
    "      y[col] = y[col].astype('float32')\n",
    "\n",
    "    print(f\"features X: {X.shape[0]} samples, {X.shape[1]} attributes\")\n",
    "    print(f\"targets y: {y.shape} samples\")\n",
    "    return X, y\n",
    "\n",
    "class PandasDataSet(TensorDataset):\n",
    "    def __init__(self, *dataframes):\n",
    "        tensors = (self._df_to_tensor(df) for df in dataframes)\n",
    "        super(PandasDataSet, self).__init__(*tensors)\n",
    "\n",
    "    def _df_to_tensor(self, df):\n",
    "        if isinstance(df, pd.Series):\n",
    "            df = df.to_frame('dummy')\n",
    "        return torch.from_numpy(df.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "Li30_V7YPtg-",
    "outputId": "b554e383-a5ba-4912-8900-a9ee9fe59c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features X: 30940 samples, 95 attributes\n",
      "targets y: (30940, 1) samples\n",
      "        age  education_num  capital_gain  capital_loss  hours_per_week  \\\n",
      "27719  17.0            7.0           0.0           0.0            12.0   \n",
      "936    47.0           14.0           0.0           0.0            25.0   \n",
      "3936   46.0           11.0           0.0           0.0            38.0   \n",
      "8500   45.0           14.0           0.0        1902.0            50.0   \n",
      "3882   51.0           10.0           0.0           0.0            40.0   \n",
      "\n",
      "       workclass_Local-gov  workclass_Never-worked  workclass_Private  \\\n",
      "27719                  0.0                     0.0                1.0   \n",
      "936                    0.0                     0.0                1.0   \n",
      "3936                   0.0                     0.0                0.0   \n",
      "8500                   0.0                     0.0                1.0   \n",
      "3882                   0.0                     0.0                1.0   \n",
      "\n",
      "       workclass_Self-emp-inc  workclass_Self-emp-not-inc  ...  \\\n",
      "27719                     0.0                         0.0  ...   \n",
      "936                       0.0                         0.0  ...   \n",
      "3936                      0.0                         0.0  ...   \n",
      "8500                      0.0                         0.0  ...   \n",
      "3882                      0.0                         0.0  ...   \n",
      "\n",
      "       country_Puerto-Rico  country_Scotland  country_South  country_Taiwan  \\\n",
      "27719                  0.0               0.0            0.0             0.0   \n",
      "936                    0.0               0.0            0.0             0.0   \n",
      "3936                   0.0               0.0            0.0             0.0   \n",
      "8500                   0.0               0.0            0.0             0.0   \n",
      "3882                   0.0               0.0            0.0             0.0   \n",
      "\n",
      "       country_Thailand  country_Trinadad&Tobago  country_United-States  \\\n",
      "27719               0.0                      0.0                    1.0   \n",
      "936                 0.0                      0.0                    1.0   \n",
      "3936                0.0                      0.0                    1.0   \n",
      "8500                0.0                      0.0                    1.0   \n",
      "3882                0.0                      0.0                    1.0   \n",
      "\n",
      "       country_Unknown  country_Vietnam  country_Yugoslavia  \n",
      "27719              0.0              0.0                 0.0  \n",
      "936                0.0              0.0                 0.0  \n",
      "3936               0.0              0.0                 0.0  \n",
      "8500               0.0              0.0                 0.0  \n",
      "3882               0.0              0.0                 0.0  \n",
      "\n",
      "[5 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "# load adult data set\n",
    "path = 'adult.data'\n",
    "# path = 'adult.data'\n",
    "X, y = load_adult_data(path)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# split into train/test set\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, stratify=y, random_state=7)\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "xIajW8C6RRlz",
    "outputId": "80b2c04d-0728-480c-fe05-a96124a967e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training samples: 24752\n",
      "# testing samples: 6188\n",
      "# batches: 247\n",
      "# training samples: 6188\n",
      "# batches: 61\n"
     ]
    }
   ],
   "source": [
    "# Set up training & testing data\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data = PandasDataSet(X_train, y_train)\n",
    "test_data = PandasDataSet(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "# test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "print('# training samples:', len(train_data))\n",
    "print('# testing samples:', len(test_data))\n",
    "print('# batches:', len(train_loader))\n",
    "\n",
    "print('# training samples:', len(test_data))\n",
    "print('# batches:', len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define accuracy & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, test_loader):\n",
    "    correct = 0\n",
    "\n",
    "    for examples, labels in test_loader:\n",
    "        output = model.forward(examples)\n",
    "        batch_correct = torch.sum(torch.abs(output - labels) < 0.5)\n",
    "        correct += batch_correct\n",
    "\n",
    "    acc = float(correct)/len(test_data)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=32, p_dropout=0.2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p_dropout),\n",
    "            nn.Linear(n_hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.network(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The calculation for immediate sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_immediate_sensitivity(model, criterion, inputs, labels, epoch):\n",
    "    inp = Variable(inputs, requires_grad=True)\n",
    "    \n",
    "    outputs = model.forward(inp)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # (1) first-order gradient (wrt parameters)\n",
    "    first_order_grads = torch.autograd.grad(loss, model.parameters(), retain_graph=True, create_graph=True)\n",
    "    \n",
    "    # (2) L2 norm of the gradient from (1)\n",
    "    grad_l2_norm = torch.norm(torch.cat([x.view(-1) for x in first_order_grads]), p = 2)\n",
    "    \n",
    "    # (3) Gradient (wrt inputs) of the L2 norm of the gradient from (2)\n",
    "    sensitivity_vec = torch.autograd.grad(grad_l2_norm, inp, retain_graph=True)[0]\n",
    "    \n",
    "    # (4) L2 norm of (3) - \"immediate sensitivity\"\n",
    "    s = [torch.norm(v, p=2).numpy().item() for v in sensitivity_vec]\n",
    "    \n",
    "    '''\n",
    "    if epoch > 5:\n",
    "        print(f\"inputs: \",inp)\n",
    "        print(f\"outputs: \", outputs)\n",
    "        print(f\"loss: \", loss)\n",
    "        print(f\"first_order_grads: \", first_order_grads)\n",
    "        print(f\"grad_l2_norm:: \", grad_l2_norm)\n",
    "        print(f\"sensitivity_vec: \", sensitivity_vec)\n",
    "        print(f\"sensitivies: \", s)\n",
    "    '''\n",
    "\n",
    "    loss.backward()\n",
    "    return loss, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model, calculating immediate sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(epsilon):\n",
    "    # reset the model\n",
    "    model = Classifier(n_features=n_features)\n",
    "    model_criterion = nn.BCELoss()\n",
    "    model_optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "    # number of epochs and iterations\n",
    "    epochs = 10\n",
    "    iters = epochs * BATCH_SIZE\n",
    "\n",
    "    # parameters for Renyi differential privacy\n",
    "    alpha = 2\n",
    "    epsilon_iter = epsilon / iters\n",
    "    \n",
    "    # plotting criteria\n",
    "    train_losses = []\n",
    "    max_sensitivities = []\n",
    "    mean_sensitivities = []\n",
    "    max_sigmas = []\n",
    "    mean_sigmas = []\n",
    "    test_accs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Start of epoch %d' % (epoch,))\n",
    "        all_sensitivities = []\n",
    "        sigmas = []\n",
    "\n",
    "        for x_batch_train, y_batch_train in train_loader:\n",
    "            model_optimizer.zero_grad()\n",
    "            loss, batch_sensitivities = grad_immediate_sensitivity(model, model_criterion, x_batch_train, y_batch_train,epoch)\n",
    "            train_losses.append(loss)\n",
    "            \n",
    "            batch_sensitivity = np.max(batch_sensitivities) / BATCH_SIZE\n",
    "            all_sensitivities.append(batch_sensitivity)\n",
    "\n",
    "            # this is the scale of the Gaussian noise to be added to the batch gradient\n",
    "            sigma = np.sqrt((batch_sensitivity**2 * alpha) / (2 * epsilon_iter))\n",
    "\n",
    "            sigmas.append(sigma)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p.grad += (sigma * torch.randn(1))\n",
    "\n",
    "            model_optimizer.step()\n",
    "\n",
    "        max_sensitivities.append(np.max(all_sensitivities))\n",
    "        print(\"Max batch sensitivity for the epoch:\", max_sensitivities[-1])\n",
    "        mean_sensitivities.append(np.mean(all_sensitivities))\n",
    "        print(\"Mean batch sensitivity for the epoch:\", mean_sensitivities[-1])\n",
    "        max_sigmas.append(np.max(sigmas))\n",
    "        print(\"Max sigma for the epoch:\", max_sigmas[-1])\n",
    "        mean_sigmas.append(np.mean(sigmas))\n",
    "        print(\"Mean sigma for the epoch:\", mean_sigmas[-1])\n",
    "        test_accs.append(accuracy(model, test_loader))\n",
    "        print(\"Accuracy:\", test_accs[-1])\n",
    "    return accuracy(model, test_loader), (train_losses, max_sensitivities, mean_sensitivities, max_sigmas, mean_sigmas, test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "> \u001b[0;32m<ipython-input-11-d09695c859f3>\u001b[0m(3)\u001b[0;36mgrad_immediate_sensitivity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      1 \u001b[0;31m\u001b[0;32mdef\u001b[0m \u001b[0mgrad_immediate_sensitivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 3 \u001b[0;31m    \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-11-d09695c859f3>\u001b[0m(5)\u001b[0;36mgrad_immediate_sensitivity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      3 \u001b[0;31m    \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m    \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m    \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> inp\n",
      "tensor([[21., 12.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [33.,  4.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [65.,  9.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [33.,  9.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [32., 13.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [28., 10.,  0.,  ...,  0.,  0.,  0.]], requires_grad=True)\n",
      "ipdb> inp.shape\n",
      "torch.Size([100, 95])\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-11-d09695c859f3>\u001b[0m(6)\u001b[0;36mgrad_immediate_sensitivity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      4 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 6 \u001b[0;31m    \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m    \u001b[0;31m# (1) first-order gradient (wrt parameters)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> outputs\n",
      "tensor([[3.7280e-01],\n",
      "        [3.3565e-01],\n",
      "        [2.0167e-01],\n",
      "        [3.1150e-01],\n",
      "        [3.5647e-01],\n",
      "        [2.9154e-01],\n",
      "        [3.3897e-01],\n",
      "        [4.1631e-01],\n",
      "        [3.9188e-01],\n",
      "        [2.7852e-01],\n",
      "        [2.9115e-01],\n",
      "        [9.8791e-19],\n",
      "        [2.2139e-01],\n",
      "        [3.2473e-01],\n",
      "        [3.2778e-01],\n",
      "        [2.3856e-01],\n",
      "        [3.2129e-01],\n",
      "        [2.4063e-01],\n",
      "        [2.3896e-01],\n",
      "        [3.2047e-01],\n",
      "        [3.2268e-01],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [1.9980e-09],\n",
      "        [2.2939e-27],\n",
      "        [2.9240e-01],\n",
      "        [4.1524e-01],\n",
      "        [2.9174e-01],\n",
      "        [2.2596e-01],\n",
      "        [3.7104e-01],\n",
      "        [4.2675e-01],\n",
      "        [2.3337e-01],\n",
      "        [3.7239e-01],\n",
      "        [4.1368e-01],\n",
      "        [3.4400e-01],\n",
      "        [3.7492e-01],\n",
      "        [3.2578e-01],\n",
      "        [3.9258e-01],\n",
      "        [3.1160e-01],\n",
      "        [0.0000e+00],\n",
      "        [3.3709e-01],\n",
      "        [3.9405e-01],\n",
      "        [3.1949e-01],\n",
      "        [3.5392e-01],\n",
      "        [2.7716e-01],\n",
      "        [3.8671e-01],\n",
      "        [3.7136e-01],\n",
      "        [3.6528e-01],\n",
      "        [4.0431e-01],\n",
      "        [4.3740e-01],\n",
      "        [4.1063e-01],\n",
      "        [3.7953e-01],\n",
      "        [2.9523e-01],\n",
      "        [3.2855e-01],\n",
      "        [5.8926e-11],\n",
      "        [3.2325e-01],\n",
      "        [3.1172e-01],\n",
      "        [2.7918e-01],\n",
      "        [4.1795e-01],\n",
      "        [4.3192e-01],\n",
      "        [3.2183e-01],\n",
      "        [2.7464e-01],\n",
      "        [4.1875e-01],\n",
      "        [3.7989e-01],\n",
      "        [2.6975e-01],\n",
      "        [3.2237e-01],\n",
      "        [7.9657e-06],\n",
      "        [3.2137e-01],\n",
      "        [2.9310e-01],\n",
      "        [2.4304e-01],\n",
      "        [3.5697e-01],\n",
      "        [1.6722e-01],\n",
      "        [3.3335e-01],\n",
      "        [2.8816e-01],\n",
      "        [2.2943e-01],\n",
      "        [3.0598e-01],\n",
      "        [3.1833e-01],\n",
      "        [1.5686e-11],\n",
      "        [2.8010e-05],\n",
      "        [4.2482e-01],\n",
      "        [3.8366e-01],\n",
      "        [3.6685e-01],\n",
      "        [2.5035e-01],\n",
      "        [4.2288e-01],\n",
      "        [3.1076e-01],\n",
      "        [2.8285e-01],\n",
      "        [2.4980e-01],\n",
      "        [5.1677e-01],\n",
      "        [3.5601e-01],\n",
      "        [2.5696e-01],\n",
      "        [3.2838e-01],\n",
      "        [2.4196e-01],\n",
      "        [1.9353e-36],\n",
      "        [2.5958e-01],\n",
      "        [4.0551e-01],\n",
      "        [1.8767e-01],\n",
      "        [1.8429e-01],\n",
      "        [3.3105e-01],\n",
      "        [3.9871e-07],\n",
      "        [2.6421e-01]], grad_fn=<SigmoidBackward>)\n",
      "ipdb> outputs.shape\n",
      "torch.Size([100, 1])\n",
      "ipdb> loss\n",
      "*** NameError: name 'loss' is not defined\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-11-d09695c859f3>\u001b[0m(9)\u001b[0;36mgrad_immediate_sensitivity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      7 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m    \u001b[0;31m# (1) first-order gradient (wrt parameters)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 9 \u001b[0;31m    \u001b[0mfirst_order_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m    \u001b[0;31m# (2) L2 norm of the gradient from (1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> loss\n",
      "tensor(4.8368, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "ipdb> loss.shape\n",
      "torch.Size([])\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-11-d09695c859f3>\u001b[0m(12)\u001b[0;36mgrad_immediate_sensitivity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     10 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m    \u001b[0;31m# (2) L2 norm of the gradient from (1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 12 \u001b[0;31m    \u001b[0mgrad_l2_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfirst_order_grads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m    \u001b[0;31m# (3) Gradient (wrt inputs) of the L2 norm of the gradient from (2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> first_order_grads\n",
      "(tensor([[ 1.1807e-02, -8.3038e-04, -9.1315e-10,  ..., -1.1627e-04,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 5.9022e-02,  1.3360e-02,  0.0000e+00,  ...,  6.7357e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 4.4895e-02,  1.7199e-02, -1.1803e-09,  ..., -1.3135e-15,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 9.0787e-02,  2.0865e-02, -2.5949e-09,  ..., -6.7996e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 6.8043e-03,  9.5420e-03,  0.0000e+00,  ...,  1.8873e-04,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.2801e-02, -8.2861e-03, -5.5224e-12,  ..., -2.5379e-15,\n",
      "          0.0000e+00,  0.0000e+00]], grad_fn=<TBackward>), tensor([-1.2313e-03,  1.7313e-03,  1.2201e-03, -2.2022e-03, -2.3602e-04,\n",
      "        -3.3513e-04,  6.0864e-06, -5.4566e-15,  0.0000e+00,  4.5198e-04,\n",
      "         3.4942e-04,  0.0000e+00, -7.7745e-04, -3.1709e-03,  9.9410e-04,\n",
      "         1.1959e-03,  1.8502e-04, -5.9798e-04,  5.0871e-04, -7.9152e-04,\n",
      "        -5.7678e-05, -4.0212e-13,  0.0000e+00, -6.8118e-04, -2.2326e-05,\n",
      "         2.7706e-13, -6.0590e-05, -8.5889e-04, -1.9068e-03,  2.3585e-03,\n",
      "         1.2570e-03, -2.6082e-03], grad_fn=<ViewBackward>), tensor([[ 5.7021e-04,  3.9784e-03, -1.5068e-01,  ..., -1.1106e-04,\n",
      "         -1.2926e-03, -6.8452e-02],\n",
      "        [-1.2443e-02, -3.9747e-03,  1.4120e-01,  ..., -1.6808e-03,\n",
      "         -1.0768e-03,  5.7609e-02],\n",
      "        [-4.4274e-03,  3.0092e-03, -3.4252e-01,  ..., -1.2586e-04,\n",
      "          2.0290e-03, -1.6035e-01],\n",
      "        ...,\n",
      "        [ 1.5491e-02,  1.6765e-02,  2.5022e-02,  ...,  1.9415e-03,\n",
      "          1.5365e-03,  1.3447e-02],\n",
      "        [-1.4748e-03,  1.3073e-05,  4.5004e-02,  ..., -3.0716e-04,\n",
      "         -5.7330e-05,  2.0174e-02],\n",
      "        [-6.4070e-03, -3.4990e-03,  4.8380e-05,  ..., -5.3885e-04,\n",
      "         -6.4499e-04, -7.6481e-04]], grad_fn=<TBackward>), tensor([ 8.9950e-04, -2.0563e-03, -2.6120e-03,  6.7336e-04,  3.7771e-04,\n",
      "        -2.1369e-03,  1.1624e-04,  7.0011e-04, -1.6961e-03,  1.3114e-03,\n",
      "        -5.4675e-03, -4.8811e-03,  4.0986e-03,  1.0594e-03,  0.0000e+00,\n",
      "         7.5432e-04, -1.5438e-03, -1.8649e-03,  2.0261e-03, -6.2406e-03,\n",
      "        -4.7884e-05,  4.6436e-03, -1.3670e-03, -3.1881e-05, -3.2865e-03,\n",
      "         5.3526e-04,  7.3337e-15,  6.0051e-04, -6.2936e-15,  2.1263e-03,\n",
      "        -1.6737e-04, -6.1680e-04], grad_fn=<ViewBackward>), tensor([[ 1.9854e-03,  1.2903e-02, -7.0354e-03,  ...,  6.9008e-02,\n",
      "          7.0244e-02, -2.5817e-03],\n",
      "        [ 0.0000e+00, -5.7874e-04,  1.2442e-03,  ..., -2.0828e-03,\n",
      "         -1.1180e-05,  5.9710e-04],\n",
      "        [-1.9539e-03, -6.0155e-03, -6.5097e-03,  ...,  1.1893e-02,\n",
      "         -6.7092e-04, -2.4100e-03],\n",
      "        ...,\n",
      "        [ 1.4600e-03,  1.6440e-02, -5.1819e-04,  ...,  9.1362e-02,\n",
      "         -2.2783e-04, -9.9550e-04],\n",
      "        [ 6.1527e-04,  3.4214e-03, -4.8332e-04,  ...,  1.6905e-02,\n",
      "          1.9621e-02, -9.0212e-04],\n",
      "        [-2.4898e-03, -2.3844e-02,  1.1817e-02,  ..., -1.1720e-01,\n",
      "          7.4222e-04,  5.1330e-03]], grad_fn=<TBackward>), tensor([-7.3805e-03, -8.0770e-04, -8.0268e-03,  1.9383e-03,  1.3615e-02,\n",
      "         7.3148e-04, -3.3585e-03, -1.5996e-03,  1.2425e-03,  2.1972e-03,\n",
      "         1.0848e-03,  1.9269e-03, -1.6734e-03, -8.6640e-03, -1.8660e-03,\n",
      "        -8.6933e-04,  2.6103e-03,  4.3367e-04, -2.2997e-03, -1.1081e-02,\n",
      "         3.3374e-03,  4.8108e-04,  2.1112e-03, -1.1761e-03,  6.6273e-05,\n",
      "        -7.2863e-03, -9.7181e-04, -1.1116e-02,  5.3980e-04, -2.2144e-03,\n",
      "        -1.5205e-03,  4.3190e-03], grad_fn=<ViewBackward>), tensor([[-0.4871,  0.0022, -0.2122, -0.4963, -0.0079,  0.0016, -0.1426, -0.0030,\n",
      "         -0.2041, -0.0355, -0.3106, -0.0006,  0.0038,  0.0173, -0.1945, -0.1579,\n",
      "         -0.0018, -0.0248, -0.3592, -0.2386, -0.5788, -0.0281, -0.2032, -0.4177,\n",
      "         -0.2582, -0.5730, -0.1404, -0.1039, -0.0984, -0.2553, -0.2761, -0.0476]],\n",
      "       grad_fn=<TBackward>), tensor([0.0663], grad_fn=<ViewBackward>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> len(first_order_grads)\n",
      "8\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-11-d09695c859f3>\u001b[0m(15)\u001b[0;36mgrad_immediate_sensitivity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     13 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     14 \u001b[0;31m    \u001b[0;31m# (3) Gradient (wrt inputs) of the L2 norm of the gradient from (2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 15 \u001b[0;31m    \u001b[0msensitivity_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_l2_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m    \u001b[0;31m# (4) L2 norm of (3) - \"immediate sensitivity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> grad_l2_norm\n",
      "tensor(6.0320, grad_fn=<NormBackward0>)\n",
      "ipdb> grad_l2_norm.shape\n",
      "torch.Size([])\n",
      "ipdb> inp.shape\n",
      "torch.Size([100, 95])\n",
      "ipdb> inp.shape\n",
      "torch.Size([100, 95])\n",
      "ipdb> loss\n",
      "tensor(4.8368, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "ipdb> outputs.shape\n",
      "torch.Size([100, 1])\n",
      "ipdb> loss\n",
      "tensor(4.8368, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "ipdb> first_order_grads.shape\n",
      "*** AttributeError: 'tuple' object has no attribute 'shape'\n",
      "ipdb> first_order_grads\n",
      "(tensor([[ 1.1807e-02, -8.3038e-04, -9.1315e-10,  ..., -1.1627e-04,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 5.9022e-02,  1.3360e-02,  0.0000e+00,  ...,  6.7357e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 4.4895e-02,  1.7199e-02, -1.1803e-09,  ..., -1.3135e-15,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 9.0787e-02,  2.0865e-02, -2.5949e-09,  ..., -6.7996e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 6.8043e-03,  9.5420e-03,  0.0000e+00,  ...,  1.8873e-04,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.2801e-02, -8.2861e-03, -5.5224e-12,  ..., -2.5379e-15,\n",
      "          0.0000e+00,  0.0000e+00]], grad_fn=<TBackward>), tensor([-1.2313e-03,  1.7313e-03,  1.2201e-03, -2.2022e-03, -2.3602e-04,\n",
      "        -3.3513e-04,  6.0864e-06, -5.4566e-15,  0.0000e+00,  4.5198e-04,\n",
      "         3.4942e-04,  0.0000e+00, -7.7745e-04, -3.1709e-03,  9.9410e-04,\n",
      "         1.1959e-03,  1.8502e-04, -5.9798e-04,  5.0871e-04, -7.9152e-04,\n",
      "        -5.7678e-05, -4.0212e-13,  0.0000e+00, -6.8118e-04, -2.2326e-05,\n",
      "         2.7706e-13, -6.0590e-05, -8.5889e-04, -1.9068e-03,  2.3585e-03,\n",
      "         1.2570e-03, -2.6082e-03], grad_fn=<ViewBackward>), tensor([[ 5.7021e-04,  3.9784e-03, -1.5068e-01,  ..., -1.1106e-04,\n",
      "         -1.2926e-03, -6.8452e-02],\n",
      "        [-1.2443e-02, -3.9747e-03,  1.4120e-01,  ..., -1.6808e-03,\n",
      "         -1.0768e-03,  5.7609e-02],\n",
      "        [-4.4274e-03,  3.0092e-03, -3.4252e-01,  ..., -1.2586e-04,\n",
      "          2.0290e-03, -1.6035e-01],\n",
      "        ...,\n",
      "        [ 1.5491e-02,  1.6765e-02,  2.5022e-02,  ...,  1.9415e-03,\n",
      "          1.5365e-03,  1.3447e-02],\n",
      "        [-1.4748e-03,  1.3073e-05,  4.5004e-02,  ..., -3.0716e-04,\n",
      "         -5.7330e-05,  2.0174e-02],\n",
      "        [-6.4070e-03, -3.4990e-03,  4.8380e-05,  ..., -5.3885e-04,\n",
      "         -6.4499e-04, -7.6481e-04]], grad_fn=<TBackward>), tensor([ 8.9950e-04, -2.0563e-03, -2.6120e-03,  6.7336e-04,  3.7771e-04,\n",
      "        -2.1369e-03,  1.1624e-04,  7.0011e-04, -1.6961e-03,  1.3114e-03,\n",
      "        -5.4675e-03, -4.8811e-03,  4.0986e-03,  1.0594e-03,  0.0000e+00,\n",
      "         7.5432e-04, -1.5438e-03, -1.8649e-03,  2.0261e-03, -6.2406e-03,\n",
      "        -4.7884e-05,  4.6436e-03, -1.3670e-03, -3.1881e-05, -3.2865e-03,\n",
      "         5.3526e-04,  7.3337e-15,  6.0051e-04, -6.2936e-15,  2.1263e-03,\n",
      "        -1.6737e-04, -6.1680e-04], grad_fn=<ViewBackward>), tensor([[ 1.9854e-03,  1.2903e-02, -7.0354e-03,  ...,  6.9008e-02,\n",
      "          7.0244e-02, -2.5817e-03],\n",
      "        [ 0.0000e+00, -5.7874e-04,  1.2442e-03,  ..., -2.0828e-03,\n",
      "         -1.1180e-05,  5.9710e-04],\n",
      "        [-1.9539e-03, -6.0155e-03, -6.5097e-03,  ...,  1.1893e-02,\n",
      "         -6.7092e-04, -2.4100e-03],\n",
      "        ...,\n",
      "        [ 1.4600e-03,  1.6440e-02, -5.1819e-04,  ...,  9.1362e-02,\n",
      "         -2.2783e-04, -9.9550e-04],\n",
      "        [ 6.1527e-04,  3.4214e-03, -4.8332e-04,  ...,  1.6905e-02,\n",
      "          1.9621e-02, -9.0212e-04],\n",
      "        [-2.4898e-03, -2.3844e-02,  1.1817e-02,  ..., -1.1720e-01,\n",
      "          7.4222e-04,  5.1330e-03]], grad_fn=<TBackward>), tensor([-7.3805e-03, -8.0770e-04, -8.0268e-03,  1.9383e-03,  1.3615e-02,\n",
      "         7.3148e-04, -3.3585e-03, -1.5996e-03,  1.2425e-03,  2.1972e-03,\n",
      "         1.0848e-03,  1.9269e-03, -1.6734e-03, -8.6640e-03, -1.8660e-03,\n",
      "        -8.6933e-04,  2.6103e-03,  4.3367e-04, -2.2997e-03, -1.1081e-02,\n",
      "         3.3374e-03,  4.8108e-04,  2.1112e-03, -1.1761e-03,  6.6273e-05,\n",
      "        -7.2863e-03, -9.7181e-04, -1.1116e-02,  5.3980e-04, -2.2144e-03,\n",
      "        -1.5205e-03,  4.3190e-03], grad_fn=<ViewBackward>), tensor([[-0.4871,  0.0022, -0.2122, -0.4963, -0.0079,  0.0016, -0.1426, -0.0030,\n",
      "         -0.2041, -0.0355, -0.3106, -0.0006,  0.0038,  0.0173, -0.1945, -0.1579,\n",
      "         -0.0018, -0.0248, -0.3592, -0.2386, -0.5788, -0.0281, -0.2032, -0.4177,\n",
      "         -0.2582, -0.5730, -0.1404, -0.1039, -0.0984, -0.2553, -0.2761, -0.0476]],\n",
      "       grad_fn=<TBackward>), tensor([0.0663], grad_fn=<ViewBackward>))\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-11-d09695c859f3>\u001b[0m(18)\u001b[0;36mgrad_immediate_sensitivity\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     16 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m    \u001b[0;31m# (4) L2 norm of (3) - \"immediate sensitivity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 18 \u001b[0;31m    \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msensitivity_vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m    '''\n",
      "\u001b[0m\n",
      "ipdb> first_order_grads[0]\n",
      "tensor([[ 1.1807e-02, -8.3038e-04, -9.1315e-10,  ..., -1.1627e-04,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 5.9022e-02,  1.3360e-02,  0.0000e+00,  ...,  6.7357e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 4.4895e-02,  1.7199e-02, -1.1803e-09,  ..., -1.3135e-15,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 9.0787e-02,  2.0865e-02, -2.5949e-09,  ..., -6.7996e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 6.8043e-03,  9.5420e-03,  0.0000e+00,  ...,  1.8873e-04,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.2801e-02, -8.2861e-03, -5.5224e-12,  ..., -2.5379e-15,\n",
      "          0.0000e+00,  0.0000e+00]], grad_fn=<TBackward>)\n",
      "ipdb> first_order_grads[0].shape\n",
      "torch.Size([32, 95])\n",
      "ipdb> first_order_grads[1]\n",
      "tensor([-1.2313e-03,  1.7313e-03,  1.2201e-03, -2.2022e-03, -2.3602e-04,\n",
      "        -3.3513e-04,  6.0864e-06, -5.4566e-15,  0.0000e+00,  4.5198e-04,\n",
      "         3.4942e-04,  0.0000e+00, -7.7745e-04, -3.1709e-03,  9.9410e-04,\n",
      "         1.1959e-03,  1.8502e-04, -5.9798e-04,  5.0871e-04, -7.9152e-04,\n",
      "        -5.7678e-05, -4.0212e-13,  0.0000e+00, -6.8118e-04, -2.2326e-05,\n",
      "         2.7706e-13, -6.0590e-05, -8.5889e-04, -1.9068e-03,  2.3585e-03,\n",
      "         1.2570e-03, -2.6082e-03], grad_fn=<ViewBackward>)\n",
      "ipdb> first_order_grads[1].shape\n",
      "torch.Size([32])\n",
      "ipdb> grad_l2_norm\n",
      "tensor(6.0320, grad_fn=<NormBackward0>)\n",
      "ipdb> inp.shape\n",
      "torch.Size([100, 95])\n",
      "ipdb> inp\n",
      "tensor([[21., 12.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [33.,  4.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [65.,  9.,  0.,  ...,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [33.,  9.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [32., 13.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [28., 10.,  0.,  ...,  0.,  0.,  0.]], requires_grad=True)\n",
      "ipdb> torch.autograd.grad(grad_l2_norm, inp, retain_graph=True)[0]\n",
      "tensor([[-7.7125e-05, -1.5092e-05, -6.6066e-05,  ..., -1.1028e-05,\n",
      "         -3.5113e-06, -2.0737e-05],\n",
      "        [-2.2762e-05,  1.3393e-06,  1.6113e-06,  ..., -7.5153e-06,\n",
      "         -5.0404e-06, -1.3573e-05],\n",
      "        [-2.2760e-06,  1.8332e-06, -9.6835e-07,  ...,  1.0040e-05,\n",
      "          2.0354e-06, -9.2110e-06],\n",
      "        ...,\n",
      "        [-2.0923e-05, -4.8644e-06, -8.5378e-06,  ..., -1.2858e-05,\n",
      "         -1.5091e-06, -2.3135e-05],\n",
      "        [ 1.5430e-04, -3.1957e-06,  1.1268e-04,  ..., -8.2481e-05,\n",
      "          6.0634e-05,  8.1754e-05],\n",
      "        [-2.7630e-05, -1.0186e-05, -2.5669e-05,  ...,  6.1633e-06,\n",
      "          3.1641e-06, -6.9897e-06]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> grad_l2_norm.shape\n",
      "torch.Size([])\n",
      "ipdb> grad_l2_norm\n",
      "tensor(6.0320, grad_fn=<NormBackward0>)\n",
      "ipdb> first_order_grads\n",
      "(tensor([[ 1.1807e-02, -8.3038e-04, -9.1315e-10,  ..., -1.1627e-04,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 5.9022e-02,  1.3360e-02,  0.0000e+00,  ...,  6.7357e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 4.4895e-02,  1.7199e-02, -1.1803e-09,  ..., -1.3135e-15,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 9.0787e-02,  2.0865e-02, -2.5949e-09,  ..., -6.7996e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 6.8043e-03,  9.5420e-03,  0.0000e+00,  ...,  1.8873e-04,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.2801e-02, -8.2861e-03, -5.5224e-12,  ..., -2.5379e-15,\n",
      "          0.0000e+00,  0.0000e+00]], grad_fn=<TBackward>), tensor([-1.2313e-03,  1.7313e-03,  1.2201e-03, -2.2022e-03, -2.3602e-04,\n",
      "        -3.3513e-04,  6.0864e-06, -5.4566e-15,  0.0000e+00,  4.5198e-04,\n",
      "         3.4942e-04,  0.0000e+00, -7.7745e-04, -3.1709e-03,  9.9410e-04,\n",
      "         1.1959e-03,  1.8502e-04, -5.9798e-04,  5.0871e-04, -7.9152e-04,\n",
      "        -5.7678e-05, -4.0212e-13,  0.0000e+00, -6.8118e-04, -2.2326e-05,\n",
      "         2.7706e-13, -6.0590e-05, -8.5889e-04, -1.9068e-03,  2.3585e-03,\n",
      "         1.2570e-03, -2.6082e-03], grad_fn=<ViewBackward>), tensor([[ 5.7021e-04,  3.9784e-03, -1.5068e-01,  ..., -1.1106e-04,\n",
      "         -1.2926e-03, -6.8452e-02],\n",
      "        [-1.2443e-02, -3.9747e-03,  1.4120e-01,  ..., -1.6808e-03,\n",
      "         -1.0768e-03,  5.7609e-02],\n",
      "        [-4.4274e-03,  3.0092e-03, -3.4252e-01,  ..., -1.2586e-04,\n",
      "          2.0290e-03, -1.6035e-01],\n",
      "        ...,\n",
      "        [ 1.5491e-02,  1.6765e-02,  2.5022e-02,  ...,  1.9415e-03,\n",
      "          1.5365e-03,  1.3447e-02],\n",
      "        [-1.4748e-03,  1.3073e-05,  4.5004e-02,  ..., -3.0716e-04,\n",
      "         -5.7330e-05,  2.0174e-02],\n",
      "        [-6.4070e-03, -3.4990e-03,  4.8380e-05,  ..., -5.3885e-04,\n",
      "         -6.4499e-04, -7.6481e-04]], grad_fn=<TBackward>), tensor([ 8.9950e-04, -2.0563e-03, -2.6120e-03,  6.7336e-04,  3.7771e-04,\n",
      "        -2.1369e-03,  1.1624e-04,  7.0011e-04, -1.6961e-03,  1.3114e-03,\n",
      "        -5.4675e-03, -4.8811e-03,  4.0986e-03,  1.0594e-03,  0.0000e+00,\n",
      "         7.5432e-04, -1.5438e-03, -1.8649e-03,  2.0261e-03, -6.2406e-03,\n",
      "        -4.7884e-05,  4.6436e-03, -1.3670e-03, -3.1881e-05, -3.2865e-03,\n",
      "         5.3526e-04,  7.3337e-15,  6.0051e-04, -6.2936e-15,  2.1263e-03,\n",
      "        -1.6737e-04, -6.1680e-04], grad_fn=<ViewBackward>), tensor([[ 1.9854e-03,  1.2903e-02, -7.0354e-03,  ...,  6.9008e-02,\n",
      "          7.0244e-02, -2.5817e-03],\n",
      "        [ 0.0000e+00, -5.7874e-04,  1.2442e-03,  ..., -2.0828e-03,\n",
      "         -1.1180e-05,  5.9710e-04],\n",
      "        [-1.9539e-03, -6.0155e-03, -6.5097e-03,  ...,  1.1893e-02,\n",
      "         -6.7092e-04, -2.4100e-03],\n",
      "        ...,\n",
      "        [ 1.4600e-03,  1.6440e-02, -5.1819e-04,  ...,  9.1362e-02,\n",
      "         -2.2783e-04, -9.9550e-04],\n",
      "        [ 6.1527e-04,  3.4214e-03, -4.8332e-04,  ...,  1.6905e-02,\n",
      "          1.9621e-02, -9.0212e-04],\n",
      "        [-2.4898e-03, -2.3844e-02,  1.1817e-02,  ..., -1.1720e-01,\n",
      "          7.4222e-04,  5.1330e-03]], grad_fn=<TBackward>), tensor([-7.3805e-03, -8.0770e-04, -8.0268e-03,  1.9383e-03,  1.3615e-02,\n",
      "         7.3148e-04, -3.3585e-03, -1.5996e-03,  1.2425e-03,  2.1972e-03,\n",
      "         1.0848e-03,  1.9269e-03, -1.6734e-03, -8.6640e-03, -1.8660e-03,\n",
      "        -8.6933e-04,  2.6103e-03,  4.3367e-04, -2.2997e-03, -1.1081e-02,\n",
      "         3.3374e-03,  4.8108e-04,  2.1112e-03, -1.1761e-03,  6.6273e-05,\n",
      "        -7.2863e-03, -9.7181e-04, -1.1116e-02,  5.3980e-04, -2.2144e-03,\n",
      "        -1.5205e-03,  4.3190e-03], grad_fn=<ViewBackward>), tensor([[-0.4871,  0.0022, -0.2122, -0.4963, -0.0079,  0.0016, -0.1426, -0.0030,\n",
      "         -0.2041, -0.0355, -0.3106, -0.0006,  0.0038,  0.0173, -0.1945, -0.1579,\n",
      "         -0.0018, -0.0248, -0.3592, -0.2386, -0.5788, -0.0281, -0.2032, -0.4177,\n",
      "         -0.2582, -0.5730, -0.1404, -0.1039, -0.0984, -0.2553, -0.2761, -0.0476]],\n",
      "       grad_fn=<TBackward>), tensor([0.0663], grad_fn=<ViewBackward>))\n",
      "ipdb> loss\n",
      "tensor(4.8368, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "epsilons = [0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "experiment_results = [run_experiment(epsilon)[0] for epsilon in epsilons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epsilons, experiment_results)\n",
    "plt.xlabel('epsilon')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "Max batch sensitivity for the epoch: 0.004964244663715363\n",
      "Mean batch sensitivity for the epoch: 0.0001396260065519579\n",
      "Max sigma for the epoch: 0.4964244663715362\n",
      "Mean sigma for the epoch: 0.01396260065519579\n",
      "Accuracy: 0.7737556561085973\n",
      "Start of epoch 1\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 95])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-13c9ff9e622f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-91-04b657127be8>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(epsilon)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0msigmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mmodel_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sensitivities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_immediate_sensitivity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_acc, info_tuple = run_experiment(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the info tuple holds: (train_losses, max_sensitivities, mean_sensitivities, max_sigmas, mean_sigmas, test_accs)\n",
    "train_losses = info_tuple[0]\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labeled data from the dataloaders don't one-hot encode the labels... so I'm making a helper function to do it.\n",
    "def one_hot_label(label,num_classes=10):\n",
    "    zeros = [0.0]*num_classes\n",
    "    zeros[label] = 1.0\n",
    "    return torch.tensor(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_accuracy(model, test_loader):\n",
    "    correct = 0\n",
    "    num_data = 0\n",
    "\n",
    "    #grab a batch from the test loader\n",
    "    for examples, labels in test_loader:\n",
    "        outputs = model.forward(examples)\n",
    "        \n",
    "        #for each output in the batch, check if the label is correct\n",
    "        for i, output in enumerate(outputs):\n",
    "            num_data += 1\n",
    "            \n",
    "            max_i = np.argmax(output.detach().numpy())\n",
    "            if max_i == labels[i]:\n",
    "                correct += 1\n",
    "\n",
    "    acc = float(correct)/num_data\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())#, target_transform=one_hot_label)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())#, target_transform=one_hot_label)\n",
    "#mnist_trainset.targets = one_hot_labels(mnist_trainset.targets,10)\n",
    "#mnist_testset.targets = one_hot_labels(mnist_testset.targets,10)\n",
    "print(len(mnist_trainset))\n",
    "print(len(mnist_testset))\n",
    "train_loader = DataLoader(mnist_trainset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_testset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "# next(iter(train_loader))[0].shape --> torch.Size([16, 1, 28, 28])\n",
    "# This means we have 16 examples of 28x28 pixels in grayscale (i.e. no rgb channels, hence the one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5])]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mnist_Classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 28, kernel_size=(5,5))\n",
    "        self.conv2 = nn.Conv2d(28, 32, kernel_size=(5,5))\n",
    "        self.fc1 = nn.Linear(32*20*20, 16)\n",
    "        self.fc2 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        # print(x.size()) --> torch.Size([16, 32, 20, 20])\n",
    "        x = x.view(-1, 32*20*20)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        return torch.softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "Max batch sensitivity for the epoch: 4.791873931884766\n",
      "Mean batch sensitivity for the epoch: 0.37617758008616414\n",
      "Max sigma for the epoch: 191.67495727539062\n",
      "Mean sigma for the epoch: 15.047103203446566\n",
      "Average train loss: 1.6594062340736389\n",
      "Accuracy: 0.8678\n",
      "Start of epoch 1\n",
      "Max batch sensitivity for the epoch: 5.71149206161499\n",
      "Mean batch sensitivity for the epoch: 0.4530361694767047\n",
      "Max sigma for the epoch: 228.4596824645996\n",
      "Mean sigma for the epoch: 18.121446779068187\n",
      "Average train loss: 1.622550270954768\n",
      "Accuracy: 0.8786\n",
      "Start of epoch 2\n",
      "Max batch sensitivity for the epoch: 8.401281356811523\n",
      "Mean batch sensitivity for the epoch: 0.5107723346344897\n",
      "Max sigma for the epoch: 336.05125427246094\n",
      "Mean sigma for the epoch: 20.430893385379584\n",
      "Average train loss: 1.6086686088562012\n",
      "Accuracy: 0.8842\n",
      "Start of epoch 3\n",
      "Max batch sensitivity for the epoch: 10.71259593963623\n",
      "Mean batch sensitivity for the epoch: 0.6279485190082322\n",
      "Max sigma for the epoch: 428.5038375854492\n",
      "Mean sigma for the epoch: 25.117940760329297\n",
      "Average train loss: 1.6011443903366724\n",
      "Accuracy: 0.8741\n",
      "Start of epoch 4\n",
      "Max batch sensitivity for the epoch: 19.2719669342041\n",
      "Mean batch sensitivity for the epoch: 0.7630856790882331\n",
      "Max sigma for the epoch: 770.8786773681641\n",
      "Mean sigma for the epoch: 30.523427163529327\n",
      "Average train loss: 1.5963327301915486\n",
      "Accuracy: 0.8847\n",
      "Start of epoch 5\n",
      "Max batch sensitivity for the epoch: 35.84457015991211\n",
      "Mean batch sensitivity for the epoch: 0.9621871027159461\n",
      "Max sigma for the epoch: 1433.7828063964844\n",
      "Mean sigma for the epoch: 38.48748410863784\n",
      "Average train loss: 1.5934974268277486\n",
      "Accuracy: 0.8828\n",
      "Start of epoch 6\n",
      "Max batch sensitivity for the epoch: 78.29666900634766\n",
      "Mean batch sensitivity for the epoch: 1.265407793706761\n",
      "Max sigma for the epoch: 3131.8667602539062\n",
      "Mean sigma for the epoch: 50.61631174827044\n",
      "Average train loss: 1.591452527881804\n",
      "Accuracy: 0.8854\n",
      "Start of epoch 7\n",
      "Max batch sensitivity for the epoch: 56.267635345458984\n",
      "Mean batch sensitivity for the epoch: 1.2817332335350256\n",
      "Max sigma for the epoch: 2250.7054138183594\n",
      "Mean sigma for the epoch: 51.269329341401026\n",
      "Average train loss: 1.5896716516931853\n",
      "Accuracy: 0.8805\n",
      "Start of epoch 8\n",
      "Max batch sensitivity for the epoch: 79.57540893554688\n",
      "Mean batch sensitivity for the epoch: 1.5569004380718627\n",
      "Max sigma for the epoch: 3183.016357421875\n",
      "Mean sigma for the epoch: 62.27601752287451\n",
      "Average train loss: 1.5883369943371526\n",
      "Accuracy: 0.8853\n",
      "Start of epoch 9\n",
      "Max batch sensitivity for the epoch: 142.23704528808594\n",
      "Mean batch sensitivity for the epoch: 1.6933716330626642\n",
      "Max sigma for the epoch: 5689.4818115234375\n",
      "Mean sigma for the epoch: 67.73486532250656\n",
      "Average train loss: 1.5874540020275116\n",
      "Accuracy: 0.8858\n"
     ]
    }
   ],
   "source": [
    "def run_mnist(epsilon):\n",
    "    # reset the model\n",
    "    model = mnist_Classifier()\n",
    "    model_criterion = nn.CrossEntropyLoss()\n",
    "    model_optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "    # number of epochs and iterations\n",
    "    epochs = 10\n",
    "    iters = epochs * BATCH_SIZE\n",
    "\n",
    "    # parameters for Renyi differential privacy\n",
    "    alpha = 2\n",
    "    epsilon_iter = epsilon / iters\n",
    "    \n",
    "    # plotting criteria\n",
    "    train_losses = []\n",
    "    max_sensitivities = []\n",
    "    mean_sensitivities = []\n",
    "    max_sigmas = []\n",
    "    mean_sigmas = []\n",
    "    test_accs = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Start of epoch %d' % (epoch,))\n",
    "        all_sensitivities = []\n",
    "        sigmas = []\n",
    "\n",
    "        for batch_id, (x_batch_train, y_batch_train) in enumerate(train_loader):\n",
    "            \n",
    "            #zero out the gradients from the previous iteration\n",
    "            model_optimizer.zero_grad()\n",
    "            \n",
    "            #compute loss and sensitivities\n",
    "            loss, batch_sensitivities = grad_immediate_sensitivity(model, model_criterion, x_batch_train, y_batch_train,epoch)\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            batch_sensitivity = np.max(batch_sensitivities) / BATCH_SIZE\n",
    "            all_sensitivities.append(batch_sensitivity)\n",
    "\n",
    "            # this is the scale of the Gaussian noise to be added to the batch gradient\n",
    "            sigma = np.sqrt((batch_sensitivity**2 * alpha) / (2 * epsilon_iter))\n",
    "\n",
    "            sigmas.append(sigma)\n",
    "            \n",
    "            '''\n",
    "            # modify the gradients\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p.grad += (sigma * torch.randn(1))\n",
    "            '''\n",
    "\n",
    "            # perform the backpropagation\n",
    "            model_optimizer.step()\n",
    "\n",
    "        max_sensitivities.append(np.max(all_sensitivities))\n",
    "        print(\"Max batch sensitivity for the epoch:\", max_sensitivities[-1])\n",
    "        mean_sensitivities.append(np.mean(all_sensitivities))\n",
    "        print(\"Mean batch sensitivity for the epoch:\", mean_sensitivities[-1])\n",
    "        max_sigmas.append(np.max(sigmas))\n",
    "        print(\"Max sigma for the epoch:\", max_sigmas[-1])\n",
    "        mean_sigmas.append(np.mean(sigmas))\n",
    "        print(\"Mean sigma for the epoch:\", mean_sigmas[-1])\n",
    "        print(\"Average train loss:\", np.mean(train_losses))\n",
    "        test_accs.append(mnist_accuracy(model, test_loader))\n",
    "        print(\"Accuracy:\", test_accs[-1])\n",
    "    return mnist_accuracy(model, test_loader), (train_losses, max_sensitivities, mean_sensitivities, max_sigmas, mean_sigmas, test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_acc, info_tuple = run_mnist(0.1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Adult_Dataset_Smoothed_Prediction_Sensitivity.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
